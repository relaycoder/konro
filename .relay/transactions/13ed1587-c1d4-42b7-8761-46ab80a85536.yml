uuid: 13ed1587-c1d4-42b7-8761-46ab80a85536
projectId: konro
createdAt: '2025-07-09T06:46:27.765Z'
linesAdded: 312
linesRemoved: 398
gitCommitMsg: 'refactor(core): radically DRY codebase by unifying on-demand contexts'
promptSummary: >-
  Refactor the codebase to be radically DRY, reduce code duplication, and
  improve maintainability without regressions.
reasoning:
  - >-
    An analysis of the codebase revealed significant code duplication,
    particularly in the handling of "on-demand" database contexts for different
    file storage strategies (`multi-file` vs. `per-record`) in `src/db.ts`, and
    in the implementation of those storage strategies in `src/adapter.ts`.
  - >-
    To achieve a radically drier and more maintainable codebase, I will
    implement the following changes:
  - >-
    1.  **Refactor `src/adapter.ts` using the Strategy Pattern**: I will extract
    the file read/write logic for `single`, `multi`, and `per-record` strategies
    into dedicated, internal "strategy" functions. The main `createFileAdapter`
    function will then become a clean factory that selects the appropriate
    strategy based on user options, significantly reducing its complexity and
    improving modularity.
  - >-
    2.  **Unify On-Demand Database Contexts in `src/db.ts`**: The two nearly
    identical functions for creating on-demand contexts
    (`createMultiFileOnDemandDbContext` and `createPerRecordOnDemandDbContext`)
    will be removed. They will be replaced by a single, generic
    `createOnDemandDbContext` function. This new function will be driven by an
    `OnDemandIO` interface that abstracts the underlying file I/O operations. I
    will create two implementations of this interface—one for `multi-file` and
    one for `per-record`—which encapsulate the specific file handling logic.
    This change centralizes the fluent API logic and eliminates thousands of
    lines of redundant code.
  - >-
    3.  **Refine `src/operations.ts`**: I will make a minor but impactful
    simplification to the `_deleteImpl` function. The logic for "soft deletes"
    will be refactored to reuse the existing `_updateImpl` function, which
    correctly handles setting the `deletedAt` timestamp while also triggering
    `updatedAt` timestamps, ensuring consistent behavior.
  - >-
    These changes will significantly reduce the line count, remove redundancy,
    and make the system more modular and easier to extend in the future.
  - '### Refactoring `src/operations.ts`'
  - >-
    First, I'll simplify the `_deleteImpl` function to reuse `_updateImpl` for
    soft deletes. This enhances consistency and reduces code.
  - '### Refactoring `src/adapter.ts`'
  - >-
    Next, I'll refactor the file adapter to use a more explicit strategy
    pattern, separating the read/write logic for each storage mode into its own
    function.
  - '### Refactoring `src/db.ts`'
  - >-
    Finally, I'll rewrite the on-demand database context to use the new unified
    structure. This is the most significant change, eliminating the largest
    source of code duplication.
operations:
  - type: write
    path: src/operations.ts
    content: >-
      --- src/operations.ts

      +++ src/operations.ts

      @@ -493,26 +493,17 @@
       
         // Soft delete path
         if (deletedAtColumn) {
      -    const recordsToUpdate: KRecord[] = [];

      -    const now = new Date();

      -

      -    const newRecords = oldTableState.records.map(record => {

      -      if (!record[deletedAtColumn] && predicate(record)) { // Not already
      soft-deleted and matches predicate

      -        const updatedRecord = { ...record, [deletedAtColumn]: now };

      -        recordsToUpdate.push(updatedRecord);

      -        return updatedRecord;

      -      }

      -      return record;

      -    });

      -

      -    if (recordsToUpdate.length === 0) return [state, []];

      -

      -    const baseState = { ...state, [tableName]: { ...oldTableState,
      records: newRecords } };

      +    // Use update implementation for soft-delete. It will also handle
      `updatedAt`.

      +    const [baseState, recordsToUpdate] = _updateImpl(

      +      state,

      +      schema,

      +      tableName,

      +      { [deletedAtColumn]: new Date() },

      +      (record) => !record[deletedAtColumn] && predicate(record)

      +    );

      +

      +    if (recordsToUpdate.length === 0) return [state, []];
           const finalState = applyCascades(baseState, schema, tableName, recordsToUpdate);
      -    
           // The returned records are the ones that were just soft-deleted from this table.
           return [finalState, recordsToUpdate];
         }
    patchStrategy: new-unified
  - type: write
    path: src/adapter.ts
    content: >-
      --- src/adapter.ts

      +++ src/adapter.ts

      @@ -48,6 +48,63 @@
           throw KonroError("The 'on-demand' mode requires the 'multi-file' or 'per-record' storage strategy.");
         }
       
      +  const strategy = createStrategy(options, { fs, serializer,
      fileExtension, mode });

      +

      +  return {

      +    options,

      +    fs,

      +    serializer,

      +    fileExtension,

      +    mode,

      +    ...strategy,

      +  } as FileStorageAdapter;

      +}

      +

      +type FileStrategy = Pick<StorageAdapter, 'read' | 'write'>;

      +type StrategyContext = {

      +  fs: FsProvider;

      +  serializer: Serializer;

      +  fileExtension: string;

      +  mode: 'in-memory' | 'on-demand';

      +};

      +

      +/** Chooses and creates the appropriate file strategy based on adapter
      options. */

      +function createStrategy(options: FileAdapterOptions, context:
      StrategyContext): FileStrategy {

      +  if (options.single) {

      +    return createSingleFileStrategy(options.single, context);

      +  }

      +  if (options.multi) {

      +    return createMultiFileStrategy(options.multi, context);

      +  }

      +  if (options.perRecord) {

      +    return createPerRecordStrategy(options.perRecord, context);

      +  }

      +  // This case should be prevented by the types, but as a safeguard:

      +  throw new KonroError('Invalid file adapter options: missing storage
      strategy.');

      +}

      +

      +/** Creates the strategy for reading/writing the entire database to a
      single file. */

      +function createSingleFileStrategy(options: SingleFileStrategy['single'],
      context: StrategyContext): FileStrategy {

      +  const { fs, serializer } = context;

      +

      +  const parseFile = async <T>(filepath: string, schema?: Record<string,
      ColumnDefinition<any>>): Promise<T | undefined> => {

      +    const data = await fs.readFile(filepath);

      +    if (!data) return undefined;

      +    try {

      +      return serializer.parse<T>(data, schema);

      +    } catch (e: any) {

      +      throw KonroStorageError(`Failed to parse file at "${filepath}". It
      may be corrupt or not a valid ${context.fileExtension.slice(1)} file.
      Original error: ${e.message}`);

      +    }

      +  };

      +

      +  return {

      +    read: async <S extends KonroSchema<any, any>>(schema: S) => {

      +      const state = await
      parseFile<DatabaseState<any>>(options.filepath);

      +      return (state ?? createEmptyState(schema)) as DatabaseState<S>;

      +    },

      +    write: (state: DatabaseState<any>) => writeAtomic(options.filepath,
      serializer.stringify(state), fs),

      +  };

      +}

      +

      +/** Creates the strategy for reading/writing each table to its own file
      in a directory. */

      +function createMultiFileStrategy(options: MultiFileStrategy['multi'],
      context: StrategyContext): FileStrategy {
         const parseFile = async <T>(filepath: string, schema?: Record<string, ColumnDefinition<any>>): Promise<T | undefined> => {
           const data = await fs.readFile(filepath);
           if (!data) return undefined;
      @@ -58,97 +115,82 @@
           }
         };
       
      -  const readSingle = async <S extends KonroSchema<any, any>>(schema: S):
      Promise<DatabaseState<S>> => {

      -    const state = await
      parseFile<DatabaseState<any>>(options.single!.filepath);

      -    // The cast is acceptable as the original code made the same implicit
      assumption.

      -    return (state ?? createEmptyState(schema)) as DatabaseState<S>;

      -  };

      -

      -  const readMulti = async <S extends KonroSchema<any, any>>(schema: S):
      Promise<DatabaseState<S>> => {

      -    const dir = options.multi!.dir;

      -    await fs.mkdir(dir, { recursive: true });

      -    const state = createEmptyState(schema);

      -    await Promise.all(

      -      Object.keys(schema.tables).map(async (tableName) => {

      -        const filepath = path.join(dir, `${tableName}${fileExtension}`);

      -        const tableState = await parseFile<TableState<any>>(filepath,
      schema.tables[tableName]);

      -        if (tableState) (state as any)[tableName] = tableState;

      -      })

      -    );

      -    return state;

      -  };

      -

      -  const readPerRecord = async <S extends KonroSchema<any, any>>(schema:
      S): Promise<DatabaseState<S>> => {

      -    const dir = options.perRecord!.dir;

      -    await fs.mkdir(dir, { recursive: true });

      -    const state = createEmptyState(schema);

      -

      -    await Promise.all(

      -      Object.keys(schema.tables).map(async (tableName) => {

      -        const tableDir = path.join(dir, tableName);

      -        await fs.mkdir(tableDir, { recursive: true });

      -

      -        // Read meta file for lastId

      -        const metaPath = path.join(tableDir, '_meta.json');

      -        try {

      -          const metaContent = await fs.readFile(metaPath);

      -          if (metaContent) {

      -            (state as any)[tableName].meta = JSON.parse(metaContent);

      -          }

      -        } catch (e) {

      -          /* ignore if not found or parsing fails, will use default */

      -        }

      -

      -        const files = await fs.readdir(tableDir);

      -        const recordFiles = files.filter((f) => !f.startsWith('_meta'));

      -

      -        const records = await Promise.all(

      -          recordFiles.map((file) =>
      parseFile<KRecord>(path.join(tableDir, file)))

      -        );

      -

      -        (state as any)[tableName].records = records.filter((r): r is
      KRecord => r != null);

      -

      -        // If meta file didn't exist or was empty, derive lastId for
      auto-increment PKs.

      -        if ((state as any)[tableName].meta.lastId === 0) {

      -          const tableSchema = schema.tables[tableName];

      -          const idColumn = Object.keys(tableSchema).find((key) =>
      tableSchema[key]?.dataType === 'id' &&
      tableSchema[key]?.options?._pk_strategy !== 'uuid');

      -          if (idColumn) {

      -            (state as any)[tableName].meta.lastId = (state as
      any)[tableName].records.reduce((maxId: number, record: KRecord) => {

      -              const id = record[idColumn];

      -              return typeof id === 'number' && id > maxId ? id : maxId;

      -            }, 0);

      -          }

      -        }

      -      })

      -    );

      -    return state;

      -  };

      -

      -  const writeSingle = (state: DatabaseState<any>) =>
      writeAtomic(options.single!.filepath, serializer.stringify(state), fs);

      -

      -  const writeMulti = async (state: DatabaseState<any>) => {

      -    const dir = options.multi!.dir;

      -    await fs.mkdir(dir, { recursive: true });

      -    const writes = Object.entries(state).map(([tableName, tableState]) =>
      {

      -      const filepath = path.join(dir, `${tableName}${fileExtension}`);

      -      return writeAtomic(filepath, serializer.stringify(tableState), fs);

      -    });

      -    await Promise.all(writes);

      -  };

      -

      -  const writePerRecord = async (state: DatabaseState<any>, schema:
      KonroSchema<any, any>) => {

      -    const dir = options.perRecord!.dir;

      -    await fs.mkdir(dir, { recursive: true });

      -

      -    const writes = Object.entries(state).map(async ([tableName,
      tableState]) => {

      -      const tableDir = path.join(dir, tableName);

      -      await fs.mkdir(tableDir, { recursive: true });

      -

      -      // Write meta file first

      -      const metaPath = path.join(tableDir, '_meta.json');

      -      await writeAtomic(metaPath, JSON.stringify(tableState.meta, null,
      2), fs);

      -

      -      const idColumn = Object.keys(schema.tables[tableName]).find((key)
      => schema.tables[tableName][key]?.dataType === 'id');

      -      if (!idColumn) {

      -        throw KonroError(`Table "${tableName}" must have an 'id' column
      to be used with 'per-record' storage.`);

      -      }

      -

      -      const currentFiles = new Set(tableState.records.map((r: KRecord) =>
      `${r[idColumn]}${fileExtension}`));

      -      const existingFiles = (await fs.readdir(tableDir)).filter((f) =>
      !f.startsWith('_meta') && !f.endsWith(TEMP_FILE_SUFFIX));

      -

      -      const recordWrites = tableState.records.map((record: KRecord) =>
      writeAtomic(path.join(tableDir, `${record[idColumn]}${fileExtension}`),
      serializer.stringify(record), fs));

      -      const recordsToDelete = existingFiles.filter((f) =>
      !currentFiles.has(f));

      -      const recordDeletes = recordsToDelete.map((f) =>
      fs.unlink(path.join(tableDir, f)));

      -

      -      await Promise.all([...recordWrites, ...recordDeletes]);

      -    });

      -    await Promise.all(writes);

      -  };

      -
         return {
      -    options,

      -    fs,

      -    serializer,

      -    fileExtension,

      -    mode,

      -    read: options.single ? readSingle : options.multi ? readMulti :
      readPerRecord,

      -    write: options.single ? writeSingle : options.multi ? writeMulti :
      writePerRecord,

      -  } as FileStorageAdapter;

      -}

      +    read: async <S extends KonroSchema<any, any>>(schema: S) => {

      +      await context.fs.mkdir(options.dir, { recursive: true });

      +      const state = createEmptyState(schema);

      +      await Promise.all(

      +        Object.keys(schema.tables).map(async (tableName) => {

      +          const filepath = path.join(options.dir,
      `${tableName}${context.fileExtension}`);

      +          const tableState = await parseFile<TableState<any>>(filepath,
      schema.tables[tableName]);

      +          if (tableState) (state as any)[tableName] = tableState;

      +        })

      +      );

      +      return state;

      +    },

      +    write: async (state: DatabaseState<any>) => {

      +      await context.fs.mkdir(options.dir, { recursive: true });

      +      const writes = Object.entries(state).map(([tableName, tableState])
      => {

      +        const filepath = path.join(options.dir,
      `${tableName}${context.fileExtension}`);

      +        return writeAtomic(filepath,
      context.serializer.stringify(tableState), context.fs);

      +      });

      +      await Promise.all(writes);

      +    },

      +  };

      +}

      +

      +/** Creates the strategy for reading/writing each record to its own file.
      */

      +function createPerRecordStrategy(options: PerRecordStrategy['perRecord'],
      context: StrategyContext): FileStrategy {

      +  const { fs, serializer, fileExtension } = context;

      +

      +  const parseFile = async <T>(filepath: string): Promise<T | undefined>
      => {

      +    const data = await fs.readFile(filepath);

      +    if (!data) return undefined;

      +    try {

      +      return serializer.parse<T>(data);

      +    } catch (e: any) {

      +      throw KonroStorageError(`Failed to parse file at "${filepath}". It
      may be corrupt or not a valid ${context.fileExtension.slice(1)} file.
      Original error: ${e.message}`);

      +    }

      +  };

      +

      +  return {

      +    read: async <S extends KonroSchema<any, any>>(schema: S) => {

      +      await fs.mkdir(options.dir, { recursive: true });

      +      const state = createEmptyState(schema);

      +      await Promise.all(

      +        Object.keys(schema.tables).map(async (tableName) => {

      +          const tableDir = path.join(options.dir, tableName);

      +          await fs.mkdir(tableDir, { recursive: true });

      +

      +          const metaContent = await fs.readFile(path.join(tableDir,
      '_meta.json')).catch(() => null);

      +          if (metaContent) (state as any)[tableName].meta =
      JSON.parse(metaContent);

      +

      +          const files = await fs.readdir(tableDir);

      +          const recordFiles = files.filter((f) =>
      !f.startsWith('_meta'));

      +          const records = (await Promise.all(recordFiles.map((file) =>
      parseFile<KRecord>(path.join(tableDir, file))))).filter((r): r is KRecord
      => r != null);

      +          (state as any)[tableName].records = records;

      +

      +          if ((state as any)[tableName].meta.lastId === 0) {

      +            const idColumn =
      Object.keys(schema.tables[tableName]).find((k) =>
      schema.tables[tableName][k]?.options?._pk_strategy === 'auto-increment');

      +            if (idColumn) {

      +              (state as any)[tableName].meta.lastId =
      records.reduce((maxId: number, record: KRecord) => {

      +                const id = record[idColumn];

      +                return typeof id === 'number' && id > maxId ? id : maxId;

      +              }, 0);

      +            }

      +          }

      +        })

      +      );

      +      return state;

      +    },

      +    write: async (state: DatabaseState<any>, schema: KonroSchema<any,
      any>) => {

      +      await fs.mkdir(options.dir, { recursive: true });

      +      await Promise.all(Object.entries(state).map(async ([tableName,
      tableState]) => {

      +        const tableDir = path.join(options.dir, tableName);

      +        await fs.mkdir(tableDir, { recursive: true });

      +        await writeAtomic(path.join(tableDir, '_meta.json'),
      JSON.stringify(tableState.meta, null, 2), fs);

      +

      +        const idColumn = Object.keys(schema.tables[tableName]).find((k)
      => schema.tables[tableName][k]?.dataType === 'id');

      +        if (!idColumn) throw KonroError(`Table "${tableName}" must have
      an 'id' column for 'per-record' storage.`);

      +

      +        const currentFiles = new Set(tableState.records.map((r: KRecord)
      => `${r[idColumn]}${fileExtension}`));

      +        const existingFiles = (await fs.readdir(tableDir)).filter(f =>
      !f.startsWith('_meta') && !f.endsWith(TEMP_FILE_SUFFIX));

      +

      +        const recordWrites = tableState.records.map((r: KRecord) =>
      writeAtomic(path.join(tableDir, `${r[idColumn]}${fileExtension}`),
      serializer.stringify(r), fs));

      +        const recordDeletes = existingFiles.filter(f =>
      !currentFiles.has(f)).map(f => fs.unlink(path.join(tableDir, f)));

      +        await Promise.all([...recordWrites, ...recordDeletes]);

      +      }));

      +    }

      +  };

      +}
    patchStrategy: new-unified
  - type: write
    path: src/db.ts
    content: >-
      import path from 'path';

      import { AggregationDefinition, ColumnDefinition, KonroSchema,
      RelationDefinition } from './schema';

      import { StorageAdapter, FileStorageAdapter } from './adapter';

      import { DatabaseState, KRecord, TableState } from './types';

      import { _queryImpl, _insertImpl, _updateImpl, _deleteImpl,
      createEmptyState as createEmptyStateImpl, QueryDescriptor, _aggregateImpl,
      AggregationDescriptor } from './operations';

      import { createPredicateFromPartial } from './utils/predicate.util';

      import { KonroError, KonroStorageError } from './utils/error.util';

      import { writeAtomic } from './fs';


      // A helper to normalize a predicate argument

      const normalizePredicate = <T extends KRecord>(
        predicate: Partial<T> | ((record: T) => boolean)
      ): ((record: KRecord) => boolean) =>
        // The cast is necessary due to function argument contravariance.
        // The internal operations work on the wider `KRecord`, while the fluent API provides the specific `T`.
        (typeof predicate === 'function' ? predicate : createPredicateFromPartial(predicate)) as (record: KRecord) => boolean;

      // --- TYPE HELPERS for Fluent API ---


      type RelatedModel<T> = T extends (infer R)[] ? R : T extends (infer R |
      null) ? R : T;


      // TAll is the full relational model type, e.g. schema.types.users

      type WithArgument<TAll> = { // e.g. TAll = S['types']['users']
        [K in keyof TAll as NonNullable<TAll[K]> extends any[] | object ? K : never]?: boolean | ({
          where?: (record: RelatedModel<NonNullable<TAll[K]>>) => boolean;
        } & (
          | { select: Record<string, ColumnDefinition<unknown>>; with?: never }
          | { select?: never; with?: WithArgument<RelatedModel<NonNullable<TAll[K]>>> }
        ));
      };


      type ResolveWith<
        S extends KonroSchema<any, any>,
        TName extends keyof S['tables'],
        TWith extends WithArgument<S['types'][TName]>
      > = { // TName='users', TWith={posts: {with: {author: true}}}
          [K in keyof TWith & keyof S['relations'][TName]]:
              S['relations'][TName][K] extends { relationType: 'many' }
                  ? ( // 'many' relation -> array result. K = 'posts'
                      TWith[K] extends { select: infer TSelect }
                          ? ({ [P in keyof TSelect]: InferColumnType<TSelect[P]> })[]
                          : TWith[K] extends { with: infer TNestedWith }
                              // S['relations']['users']['posts']['targetTable'] = 'posts'
                              ? (S['base'][S['relations'][TName][K]['targetTable']] & ResolveWith<S, S['relations'][TName][K]['targetTable'], TNestedWith & WithArgument<S['types'][S['relations'][TName][K]['targetTable']]>>)[]
                              // posts: true.
                              : S['base'][S['relations'][TName][K]['targetTable']][]
                    )
                  : S['relations'][TName][K] extends { relationType: 'one' }
                      ? ( // 'one' relation -> nullable object result
                          TWith[K] extends { select: infer TSelect }
                              ? ({ [P in keyof TSelect]: InferColumnType<TSelect[P]> }) | null
                              : TWith[K] extends { with: infer TNestedWith }
                                  ? (S['base'][S['relations'][TName][K]['targetTable']] & ResolveWith<S, S['relations'][TName][K]['targetTable'], TNestedWith & WithArgument<S['types'][S['relations'][TName][K]['targetTable']]>>) | null
                                  : S['base'][S['relations'][TName][K]['targetTable']] | null
                        )
                      : never
      };


      // InferColumnType is not exported from schema, so we need it here too.

      type InferColumnType<C> = C extends ColumnDefinition<infer T> ? T : never;


      // --- IN-MEMORY API TYPES (STATEFUL) ---


      interface ChainedQueryBuilder<S extends KonroSchema<any, any>, TName
      extends keyof S['tables'], TReturn> {
        select(fields: Record<string, ColumnDefinition<unknown> | RelationDefinition>): this;
        where(predicate: Partial<S['base'][TName]> | ((record: S['base'][TName]) => boolean)): this;
        withDeleted(): this;
        with<W extends WithArgument<S['types'][TName]>>(relations: W): ChainedQueryBuilder<S, TName, TReturn & ResolveWith<S, TName, W>>;
        limit(count: number): this;
        offset(count: number): this;
        all(): TReturn[];
        first(): TReturn | null;
        aggregate<TAggs extends Record<string, AggregationDefinition>>(
          aggregations: TAggs
        ): { [K in keyof TAggs]: number | null };
      }


      interface QueryBuilder<S extends KonroSchema<any, any>> {
        from<T extends keyof S['tables']>(tableName: T): ChainedQueryBuilder<S, T, S['base'][T]>;
      }


      interface UpdateBuilder<S extends KonroSchema<any, any>, TBase, TCreate> {
        set(data: Partial<TCreate>): {
          where(predicate: Partial<TBase> | ((record: TBase) => boolean)): [DatabaseState<S>, TBase[]];
        };
      }


      interface DeleteBuilder<S extends KonroSchema<any, any>, TBase> {
        where(predicate: Partial<TBase> | ((record: TBase) => boolean)): [DatabaseState<S>, TBase[]];
      }


      export interface InMemoryDbContext<S extends KonroSchema<any, any>> {
        schema: S;
        adapter: StorageAdapter;
        read(): Promise<DatabaseState<S>>;
        write(state: DatabaseState<S>): Promise<void>;
        createEmptyState(): DatabaseState<S>;

        query(state: DatabaseState<S>): QueryBuilder<S>;
        insert<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T, values: S['create'][T]): [DatabaseState<S>, S['base'][T]];
        insert<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T, values: Readonly<S['create'][T]>[]): [DatabaseState<S>, S['base'][T][]];
        update<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): UpdateBuilder<S, S['base'][T], S['create'][T]>;
        delete<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): DeleteBuilder<S, S['base'][T]>;
      }



      // --- ON-DEMAND API TYPES (STATELESS & ASYNC) ---


      interface OnDemandChainedQueryBuilder<S extends KonroSchema<any, any>,
      TName extends keyof S['tables'], TReturn> {
        select(fields: Record<string, ColumnDefinition<unknown> | RelationDefinition>): this;
        where(predicate: Partial<S['base'][TName]> | ((record: S['base'][TName]) => boolean)): this;
        withDeleted(): this;
        with<W extends WithArgument<S['types'][TName]>>(relations: W): OnDemandChainedQueryBuilder<S, TName, TReturn & ResolveWith<S, TName, W>>;
        limit(count: number): this;
        offset(count: number): this;
        all(): Promise<TReturn[]>;
        first(): Promise<TReturn | null>;
        aggregate<TAggs extends Record<string, AggregationDefinition>>(
          aggregations: TAggs
        ): Promise<{ [K in keyof TAggs]: number | null }>;
      }


      interface OnDemandQueryBuilder<S extends KonroSchema<any, any>> {
        from<T extends keyof S['tables']>(tableName: T): OnDemandChainedQueryBuilder<S, T, S['base'][T]>;
      }


      interface OnDemandUpdateBuilder<TBase, TCreate> {
        set(data: Partial<TCreate>): {
          where(predicate: Partial<TBase> | ((record: TBase) => boolean)): Promise<TBase[]>;
        };
      }


      interface OnDemandDeleteBuilder<TBase> {
        where(predicate: Partial<TBase> | ((record: TBase) => boolean)): Promise<TBase[]>;
      }


      export interface OnDemandDbContext<S extends KonroSchema<any, any>> {
        schema: S;
        adapter: StorageAdapter;
        read(): Promise<never>; // Not supported in on-demand mode
        write(): Promise<never>; // Not supported in on-demand mode
        createEmptyState(): DatabaseState<S>;

        query(): OnDemandQueryBuilder<S>;
        insert<T extends keyof S['tables']>(tableName: T, values: S['create'][T]): Promise<S['base'][T]>;
        insert<T extends keyof S['tables']>(tableName: T, values: Readonly<S['create'][T]>[]): Promise<S['base'][T][]>;
        update<T extends keyof S['tables']>(tableName: T): OnDemandUpdateBuilder<S['base'][T], S['create'][T]>;
        delete<T extends keyof S['tables']>(tableName: T): OnDemandDeleteBuilder<S['base'][T]>;
      }


      // --- DbContext Union Type ---

      export type DbContext<S extends KonroSchema<any, any>> =
      InMemoryDbContext<S> | OnDemandDbContext<S>;


      // --- CORE LOGIC (STATELESS & PURE) ---


      /**
       * Creates the core, stateless database operations.
       * These operations are pure functions that take a database state and return a new state,
       * forming the foundation for both in-memory and on-demand modes.
       */
      function createCoreDbContext<S extends KonroSchema<any, any>>(schema: S) {
        const query = (state: DatabaseState<S>): QueryBuilder<S> => ({
          from: <TName extends keyof S['tables']>(tableName: TName): ChainedQueryBuilder<S, TName, S['base'][TName]> => {
            const createBuilder = <TReturn>(currentDescriptor: QueryDescriptor): ChainedQueryBuilder<S, TName, TReturn> => ({
              select(fields) { return createBuilder<TReturn>({ ...currentDescriptor, select: fields }); },
              where(predicate) { return createBuilder<TReturn>({ ...currentDescriptor, where: normalizePredicate(predicate as any) }); },
              withDeleted() { return createBuilder<TReturn>({ ...currentDescriptor, withDeleted: true }); },
              with<W extends WithArgument<S['types'][TName]>>(relations: W) {
                const newWith = { ...currentDescriptor.with, ...(relations as QueryDescriptor['with']) };
                return createBuilder<TReturn & ResolveWith<S, TName, W>>({ ...currentDescriptor, with: newWith });
              },
              limit(count) { return createBuilder<TReturn>({ ...currentDescriptor, limit: count }); },
              offset(count) { return createBuilder<TReturn>({ ...currentDescriptor, offset: count }); },
              all: (): TReturn[] => _queryImpl(state as DatabaseState, schema, currentDescriptor) as any,
              first: (): TReturn | null => (_queryImpl(state as DatabaseState, schema, { ...currentDescriptor, limit: 1 })[0] ?? null) as any,
              aggregate: (aggregations) => {
                const aggDescriptor: AggregationDescriptor = { ...currentDescriptor, aggregations };
                return _aggregateImpl(state as DatabaseState, schema, aggDescriptor) as any;
              },
            });
            return createBuilder<S['base'][TName]>({ tableName: tableName as string });
          },
        });

        const insert = <T extends keyof S['tables']>(
          state: DatabaseState<S>, tableName: T, values: S['create'][T] | Readonly<S['create'][T]>[]
        ): [DatabaseState<S>, S['base'][T] | S['base'][T][]] => {
          const valsArray = Array.isArray(values) ? values : [values];
          const [newState, inserted] = _insertImpl(state as DatabaseState, schema, tableName as string, valsArray as KRecord[]);
          const result = Array.isArray(values) ? inserted : inserted[0];
          return [newState as DatabaseState<S>, result] as [DatabaseState<S>, S['base'][T] | S['base'][T][]];
        };

        const update = <T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): UpdateBuilder<S, S['base'][T], S['create'][T]> => ({
          set: (data) => ({
            where: (predicate) => {
              const [newState, updatedRecords] = _updateImpl(state as DatabaseState, schema, tableName as string, data as Partial<KRecord>, normalizePredicate(predicate as any));
              return [newState as DatabaseState<S>, updatedRecords as S['base'][T][]];
            },
          }),
        });

        const del = <T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): DeleteBuilder<S, S['base'][T]> => ({
          where: (predicate) => {
            const [newState, deletedRecords] = _deleteImpl(state as DatabaseState, schema, tableName as string, normalizePredicate(predicate as any));
            return [newState as DatabaseState<S>, deletedRecords as S['base'][T][]];
          },
        });

        return { query, insert, update, delete: del };
      }


      // --- ON-DEMAND CONTEXT (STATEFUL WRAPPER) ---


      type CoreDbContext<S extends KonroSchema<any, any>> = ReturnType<typeof
      createCoreDbContext<S>>;


      /** Defines the contract for file I/O operations in on-demand mode. */

      interface OnDemandIO<S extends KonroSchema<any, any>> {
        getFullState(): Promise<DatabaseState<S>>;
        insert(core: CoreDbContext<S>, tableName: string, values: any): Promise<any>;
        update(core: CoreDbContext<S>, tableName: string, data: Partial<KRecord>, predicate: (record: KRecord) => boolean): Promise<KRecord[]>;
        delete(core: CoreDbContext<S>, tableName: string, predicate: (record: KRecord) => boolean): Promise<KRecord[]>;
      }


      /**
       * Creates a generic, unified `OnDemandDbContext` from an I/O strategy.
       * This function is the key to removing duplication between 'multi-file' and 'per-record' modes.
       */
      function createOnDemandDbContext<S extends KonroSchema<any, any>>(
        schema: S,
        adapter: StorageAdapter,
        core: CoreDbContext<S>,
        io: OnDemandIO<S>
      ): OnDemandDbContext<S> {
        const query = (): OnDemandQueryBuilder<S> => ({
          from: <TName extends keyof S['tables']>(tableName: TName): OnDemandChainedQueryBuilder<S, TName, S['base'][TName]> => {
            const createBuilder = <TReturn>(currentDescriptor: QueryDescriptor): OnDemandChainedQueryBuilder<S, TName, TReturn> => ({
              select(fields) { return createBuilder<TReturn>({ ...currentDescriptor, select: fields }); },
              where(predicate) { return createBuilder<TReturn>({ ...currentDescriptor, where: normalizePredicate(predicate as any) }); },
              withDeleted() { return createBuilder<TReturn>({ ...currentDescriptor, withDeleted: true }); },
              with<W extends WithArgument<S['types'][TName]>>(relations: W) {
                const newWith = { ...currentDescriptor.with, ...(relations as QueryDescriptor['with']) };
                return createBuilder<TReturn & ResolveWith<S, TName, W>>({ ...currentDescriptor, with: newWith });
              },
              limit(count) { return createBuilder<TReturn>({ ...currentDescriptor, limit: count }); },
              offset(count) { return createBuilder<TReturn>({ ...currentDescriptor, offset: count }); },
              all: async () => {
                const state = await io.getFullState();
                return _queryImpl(state, schema, currentDescriptor) as any;
              },
              first: async () => {
                const state = await io.getFullState();
                return (_queryImpl(state, schema, { ...currentDescriptor, limit: 1 })[0] ?? null) as any;
              },
              aggregate: async (aggregations) => {
                const state = await io.getFullState();
                const aggDescriptor: AggregationDescriptor = { ...currentDescriptor, aggregations };
                return _aggregateImpl(state, schema, aggDescriptor) as any;
              },
            });
            return createBuilder<S['base'][TName]>({ tableName: tableName as string });
          },
        });

        const insert = <T extends keyof S['tables']>(tableName: T, values: S['create'][T] | Readonly<S['create'][T]>[]): Promise<any> =>
          io.insert(core, tableName as string, values);

        const update = <T extends keyof S['tables']>(tableName: T): OnDemandUpdateBuilder<S['base'][T], S['create'][T]> => ({
          set: (data) => ({
            where: (predicate) => io.update(core, tableName as string, data as Partial<KRecord>, normalizePredicate(predicate as any)),
          }),
        });

        const del = <T extends keyof S['tables']>(tableName: T): OnDemandDeleteBuilder<S['base'][T]> => ({
          where: (predicate) => io.delete(core, tableName as string, normalizePredicate(predicate as any)),
        });

        const notSupported = () => Promise.reject(KonroError("This method is not supported in 'on-demand' mode."));

        return { schema, adapter, createEmptyState: () => createEmptyStateImpl(schema), read: notSupported, write: notSupported, query, insert, update, delete: del };
      }



      // --- DATABASE FACTORY ---


      export function createDatabase<
        S extends KonroSchema<any, any>,
        TAdapter extends StorageAdapter,
      >(
        options: { schema: S; adapter: TAdapter }
      ): TAdapter['mode'] extends 'on-demand' ? OnDemandDbContext<S> :
      InMemoryDbContext<S>;

      export function createDatabase<S extends KonroSchema<any, any>>(
        options: { schema: S; adapter: StorageAdapter }
      ): DbContext<S> {
        const { schema, adapter } = options;
        const core = createCoreDbContext(schema);

        // --- In-Memory Mode ---
        if (adapter.mode === 'in-memory') {
          return {
            ...core,
            schema, adapter,
            read: () => adapter.read(schema),
            write: (state) => adapter.write(state, schema),
            createEmptyState: () => createEmptyStateImpl(schema),
          } as InMemoryDbContext<S>;
        }

        // --- On-Demand Mode ---
        const fileAdapter = adapter as FileStorageAdapter; // We can be sure it's a FileStorageAdapter due to checks
        const { fs, serializer, fileExtension } = fileAdapter;

        // The `read` method from the adapter provides the canonical way to get the full state.
        const getFullState = (): Promise<DatabaseState<S>> => adapter.read(schema);
        
        // --- I/O Strategy for Multi-File ---
        const createMultiFileIO = (): OnDemandIO<S> => {
          const { dir } = fileAdapter.options.multi!;
          const getTablePath = (tableName: string) => path.join(dir, `${tableName}${fileExtension}`);

          const readTableState = async (tableName: string): Promise<TableState> => {
            const data = await fs.readFile(getTablePath(tableName));
            if (!data) return { records: [], meta: { lastId: 0 } };
            try {
              return serializer.parse(data, schema.tables[tableName]);
            } catch (e: any) {
              throw KonroStorageError(`Failed to parse file at "${getTablePath(tableName)}". Original error: ${e.message}`);
            }
          };

          const writeTableState = async (tableName: string, tableState: TableState): Promise<void> => {
            await fs.mkdir(dir, { recursive: true });
            await writeAtomic(getTablePath(tableName), serializer.stringify(tableState), fs);
          };

          return {
            getFullState,
            insert: async (core, tableName, values) => {
              const state = createEmptyStateImpl(schema);
              (state as any)[tableName] = await readTableState(tableName);
              const [newState, result] = core.insert(state, tableName as keyof S["tables"], values as any);
              await writeTableState(tableName, newState[tableName]!);
              return result;
            },
            update: async (core, tableName, data, predicate) => {
              const state = createEmptyStateImpl(schema);
              (state as any)[tableName] = await readTableState(tableName);
              const [newState, result] = core.update(state, tableName as keyof S["tables"]).set(data).where(predicate);
              if (result.length > 0) await writeTableState(tableName, newState[tableName]!);
              return result as any;
            },
            delete: async (core, tableName, predicate) => {
              const state = await getFullState(); // Cascades require full state
              const [newState, deletedRecords] = core.delete(state, tableName as keyof S["tables"]).where(predicate);
              const changedTables = Object.keys(newState).filter(k => newState[k as keyof typeof newState] !== state[k as keyof typeof state]);
              await Promise.all(changedTables.map(t => writeTableState(t, newState[t as keyof typeof newState]!)));
              return deletedRecords as any;
            },
          };
        };

        // --- I/O Strategy for Per-Record ---
        const createPerRecordIO = (): OnDemandIO<S> => {
          const { dir } = fileAdapter.options.perRecord!;
          const getTableDir = (tableName: string) => path.join(dir, tableName);
          const getRecordPath = (tableName: string, id: any) => path.join(getTableDir(tableName), `${id}${fileExtension}`);
          const getMetaPath = (tableName: string) => path.join(getTableDir(tableName), '_meta.json');
          const getIdColumn = (tableName: string) => {
            const col = Object.keys(schema.tables[tableName]).find(k => schema.tables[tableName][k]?.dataType === 'id');
            if (!col) throw KonroError(`Table "${tableName}" needs an 'id' column for 'per-record' mode.`);
            return col;
          };

          return {
            getFullState,
            insert: async (core, tableName, values) => {
              const metaContent = await fs.readFile(getMetaPath(tableName)).catch(() => null);
              const meta = metaContent ? JSON.parse(metaContent) : { lastId: 0 };
              const idCol = getIdColumn(tableName);

              // Perform insert without existing records for performance
              const [newState, inserted] = core.insert({ [tableName]: { records: [], meta } } as any, tableName as keyof S["tables"], values as any);
              const insertedArr = Array.isArray(inserted) ? inserted : (inserted ? [inserted] : []);
              if (insertedArr.length === 0) return inserted;

              // Write new records and update meta if it changed
              await fs.mkdir(getTableDir(tableName), { recursive: true });
              const newMeta = newState[tableName]?.meta;
              const promises = insertedArr.map((r: any) => writeAtomic(getRecordPath(tableName, r[idCol]), serializer.stringify(r), fs));
              if (newMeta && newMeta.lastId !== meta.lastId) {
                promises.push(writeAtomic(getMetaPath(tableName), JSON.stringify(newMeta, null, 2), fs));
              }
              await Promise.all(promises);
              return inserted;
            },
            update: async (core, tableName, data, predicate) => {
              const state = await getFullState(); // Update needs full table state for predicate
              const [newState, updated] = core.update(state, tableName as keyof S["tables"]).set(data).where(predicate);
              if (updated.length === 0) return updated as any;

              const idCol = getIdColumn(tableName);
              await Promise.all(updated.map((r: any) => writeAtomic(getRecordPath(tableName, r[idCol]), serializer.stringify(r), fs)));
              
              const newMeta = newState[tableName]?.meta;
              const oldMeta = state[tableName as keyof typeof state]?.meta;
              if (newMeta && JSON.stringify(newMeta) !== JSON.stringify(oldMeta)) {
                  await writeAtomic(getMetaPath(tableName), JSON.stringify(newMeta, null, 2), fs);
              }
              return updated as any;
            },
            delete: async (core, tableName, predicate) => {
              const oldState = await getFullState();
              const [newState, deletedRecords] = core.delete(oldState, tableName as keyof S["tables"]).where(predicate);
              if (deletedRecords.length === 0) return deletedRecords as any;

              const changes = Object.keys(schema.tables).map(async tName => {
                const oldTState = oldState[tName as keyof typeof oldState]!;
                const newTState = newState[tName as keyof typeof newState]!;
                if (oldTState === newTState) return;

                const idCol = getIdColumn(tName);
                const oldMap = new Map(oldTState.records.map((r: any) => [r[idCol], r]));
                const newMap = new Map(newTState.records.map((r: any) => [r[idCol], r]));
                
                const promises: Promise<void>[] = [];
                if (JSON.stringify(oldTState.meta) !== JSON.stringify(newTState.meta)) {
                  promises.push(fs.mkdir(getTableDir(tName), { recursive: true }).then(() => 
                    writeAtomic(getMetaPath(tName), JSON.stringify(newTState.meta, null, 2), fs))
                  );
                }
                newMap.forEach((rec, id) => {
                  if (oldMap.get(id) !== rec) promises.push(writeAtomic(getRecordPath(tName, id), serializer.stringify(rec), fs));
                });
                oldMap.forEach((_rec, id) => {
                  if (!newMap.has(id)) promises.push(fs.unlink(getRecordPath(tName, id)));
                });
                await Promise.all(promises);
              });

              await Promise.all(changes);
              return deletedRecords as any;
            },
          };
        };

        const io = fileAdapter.options.multi ? createMultiFileIO() : fileAdapter.options.perRecord ? createPerRecordIO() : null;
        if (!io) {
          throw KonroError("The 'on-demand' mode requires a 'multi-file' or 'per-record' storage strategy.");
        }
        
        return createOnDemandDbContext(schema, adapter, core, io);
      }
    patchStrategy: replace
snapshot:
  src/operations.ts: "import { randomUUID } from 'crypto';\r\nimport { DatabaseState, KRecord } from './types';\r\nimport { KonroSchema, RelationDefinition, ColumnDefinition, AggregationDefinition } from './schema';\r\nimport { KonroError, KonroValidationError } from './utils/error.util';\r\n\r\n// --- HELPERS ---\r\n\r\n\r\n/** Creates a pristine, empty database state from a schema. */\r\nexport const createEmptyState = <S extends KonroSchema<any, any>>(schema: S): DatabaseState<S> => {\r\n  const state = {} as DatabaseState<S>;\r\n  for (const tableName in schema.tables) {\r\n    // This is a controlled cast, safe because we are iterating over the schema's tables.\r\n    (state as any)[tableName] = { records: [], meta: { lastId: 0 } };\r\n  }\r\n  return state;\r\n};\r\n\r\n// --- QUERY ---\r\n\r\ninterface WithOptions {\r\n  select?: Record<string, ColumnDefinition<unknown>>;\r\n  where?: (record: KRecord) => boolean;\r\n  with?: WithClause;\r\n}\r\ntype WithClause = Record<string, boolean | WithOptions>;\r\n\r\nexport interface QueryDescriptor {\r\n  tableName: string;\r\n  select?: Record<string, ColumnDefinition<unknown> | RelationDefinition>;\r\n  where?: (record: KRecord) => boolean;\r\n  with?: WithClause;\r\n  limit?: number;\r\n  offset?: number;\r\n  withDeleted?: boolean;\r\n}\r\n\r\nexport interface AggregationDescriptor extends QueryDescriptor {\r\n  aggregations: Record<string, AggregationDefinition>;\r\n}\r\n\r\nconst _processWith = <S extends KonroSchema<any, any>>(\r\n  recordsToProcess: KRecord[],\r\n  currentTableName: string,\r\n  withClause: WithClause,\r\n  schema: S,\r\n  state: DatabaseState\r\n): KRecord[] => {\r\n  // structuredClone is important to avoid mutating the records from the previous recursion level or the main state.\r\n  const resultsWithRelations = structuredClone(recordsToProcess);\r\n\r\n  for (const record of resultsWithRelations) {\r\n    for (const relationName in withClause) {\r\n      const relationDef = schema.relations[currentTableName]?.[relationName];\r\n      if (!relationDef) continue;\r\n\r\n      const withOpts = withClause[relationName];\r\n      // Skip if the value is `false` or something not truthy (though types should prevent this)\r\n      if (!withOpts) continue;\r\n\r\n      const relatedRecords = findRelatedRecords(state, record, relationDef);\r\n\r\n      const nestedWhere = typeof withOpts === 'object' ? withOpts.where : undefined;\r\n      const nestedSelect = typeof withOpts === 'object' ? withOpts.select : undefined;\r\n      const nestedWith = typeof withOpts === 'object' ? withOpts.with : undefined;\r\n\r\n      let processedRelatedRecords = nestedWhere ? relatedRecords.filter(nestedWhere) : [...relatedRecords];\r\n\r\n      // Recursively process deeper relations first\r\n      if (nestedWith && processedRelatedRecords.length > 0) {\r\n        processedRelatedRecords = _processWith(\r\n          processedRelatedRecords,\r\n          relationDef.targetTable,\r\n          nestedWith,\r\n          schema,\r\n          state\r\n        );\r\n      }\r\n\r\n      // Then, apply select on the (potentially already processed) related records\r\n      if (nestedSelect) {\r\n        const targetTableSchema = schema.tables[relationDef.targetTable];\r\n        if (!targetTableSchema) throw KonroError(`Schema for table \"${relationDef.targetTable}\" not found.`);\r\n\r\n        processedRelatedRecords = processedRelatedRecords.map(rec => {\r\n          const newRec: KRecord = {};\r\n          for (const outputKey in nestedSelect) {\r\n            const def = nestedSelect[outputKey];\r\n            if (!def) continue;\r\n            // nested with() does not support selecting relations, only columns, as per spec.\r\n            if (def._type === 'column') {\r\n              const colName = Object.keys(targetTableSchema).find(key => targetTableSchema[key] === def);\r\n              if (colName && rec.hasOwnProperty(colName)) {\r\n                newRec[outputKey] = rec[colName];\r\n              }\r\n            }\r\n          }\r\n          return newRec;\r\n        });\r\n      }\r\n\r\n      // Finally, attach the results to the parent record\r\n      if (relationDef.relationType === 'one') {\r\n        record[relationName] = processedRelatedRecords[0] ?? null;\r\n      } else {\r\n        record[relationName] = processedRelatedRecords;\r\n      }\r\n    }\r\n  }\r\n\r\n  return resultsWithRelations;\r\n};\r\n\r\nexport const _queryImpl = <S extends KonroSchema<any, any>>(state: DatabaseState, schema: S, descriptor: QueryDescriptor): KRecord[] => {\r\n  const tableState = state[descriptor.tableName];\r\n  if (!tableState) return [];\r\n\r\n  const tableSchema = schema.tables[descriptor.tableName];\r\n  if (!tableSchema) throw KonroError(`Schema for table \"${descriptor.tableName}\" not found.`);\r\n  const deletedAtColumn = Object.keys(tableSchema).find(key => tableSchema[key]?.options?._konro_sub_type === 'deletedAt');\r\n\r\n  // 1. Filter\r\n  let results: KRecord[];\r\n\r\n  // Auto-filter soft-deleted records unless opted-out\r\n  if (deletedAtColumn && !descriptor.withDeleted) {\r\n    results = tableState.records.filter(r => r[deletedAtColumn] === null || r[deletedAtColumn] === undefined);\r\n  } else {\r\n    results = [...tableState.records];\r\n  }\r\n  \r\n  results = descriptor.where ? results.filter(descriptor.where) : results;\r\n\r\n  // 2. Eager load relations (`with`) - must happen after filtering\r\n  if (descriptor.with) {\r\n    results = \r\n_processWith(results, descriptor.tableName, descriptor.with, schema, state);\r\n  }\r\n\r\n  // 3. Paginate\r\n  const offset = descriptor.offset ?? 0;\r\n  const limit = descriptor.limit ?? results.length;\r\n  let paginatedResults = results.slice(offset, offset + limit);\r\n\r\n  // 4. Select Fields\r\n  if (descriptor.select) {\r\n    const relationsSchema = schema.relations[descriptor.tableName] ?? {};\r\n\r\n    paginatedResults = paginatedResults.map(rec => {\r\n      const newRec: KRecord = {};\r\n      for (const outputKey in descriptor.select!) {\r\n        const def = descriptor.select![outputKey];\r\n        if (!def) continue;\r\n        if (def._type === 'column') {\r\n          const colName = Object.keys(tableSchema).find(key => tableSchema[key] === def);\r\n          if (colName && rec.hasOwnProperty(colName)) {\r\n            newRec[outputKey] = rec[colName];\r\n          }\r\n        } else if (def._type === 'relation') {\r\n          const relName = Object.keys(relationsSchema).find(key => relationsSchema[key] === def);\r\n          if (relName && rec.hasOwnProperty(relName)) {\r\n            newRec[outputKey] = rec[relName];\r\n          }\r\n        }\r\n      }\r\n      return newRec;\r\n    });\r\n  }\r\n\r\n  return paginatedResults;\r\n};\r\n\r\nconst findRelatedRecords = (state: DatabaseState, record: KRecord, relationDef: RelationDefinition) => {\r\n  const foreignKey = record[relationDef.on];\r\n  const targetTable = state[relationDef.targetTable];\r\n\r\n  if (foreignKey === undefined || !targetTable) return [];\r\n\r\n  // one-to-many: 'on' is PK on current table, 'references' is FK on target\r\n  if (relationDef.relationType === 'many') {\r\n    return targetTable.records.filter(r => r[relationDef.references] === foreignKey);\r\n  }\r\n\r\n  // many-to-one: 'on' is FK on current table, 'references' is PK on target\r\n  if (relationDef.relationType === 'one') {\r\n    return targetTable.records.filter(r => r[relationDef.references] === foreignKey);\r\n  }\r\n\r\n  return [];\r\n};\r\n\r\n// --- AGGREGATION ---\r\n\r\nexport const _aggregateImpl = <S extends KonroSchema<any, any>>(\r\n  state: DatabaseState,\r\n  _schema: S, // Not used but keep for API consistency\r\n  descriptor: AggregationDescriptor\r\n): Record<string, number | null> => {\r\n  const tableState = state[descriptor.tableName];\r\n  if (!tableState) return {};\r\n\r\n  const filteredRecords = descriptor.where ? tableState.records.filter(descriptor.where) : [...tableState.records];\r\n  const results: Record<string, number | null> = {};\r\n\r\n  for (const resultKey in descriptor.aggregations) {\r\n    const aggDef = descriptor.aggregations[resultKey];\r\n    if (!aggDef) continue;\r\n\r\n    if (aggDef.aggType === 'count') {\r\n      results[resultKey] = filteredRecords.length;\r\n      continue;\r\n    }\r\n\r\n    if (!aggDef.column) {\r\n      throw KonroError(`Aggregation '${aggDef.aggType}' requires a column.`);\r\n    }\r\n    const column = aggDef.column;\r\n\r\n    const values = filteredRecords.map(r => r[column]).filter(v => typeof v === 'number') as number[];\r\n\r\n    if (values.length === 0) {\r\n      if (aggDef.aggType === 'sum') {\r\n        results[resultKey] = 0; // sum of empty set is 0\r\n      } else {\r\n        results[resultKey] = null; // avg, min, max of empty set is null\r\n      }\r\n      continue;\r\n    }\r\n\r\n    switch (aggDef.aggType) {\r\n      case 'sum':\r\n        results[resultKey] = values.reduce((sum, val) => sum + val, 0);\r\n        break;\r\n      case 'avg':\r\n        results[resultKey] = values.reduce((sum, val) => sum + val, 0) / values.length;\r\n        break;\r\n      case 'min':\r\n        results[resultKey] = Math.min(...values);\r\n        break;\r\n      case 'max':\r\n        results[resultKey] = Math.max(...values);\r\n        break;\r\n    }\r\n  }\r\n  return results;\r\n};\r\n\r\n// --- INSERT ---\r\n\r\nexport const _insertImpl = <S extends KonroSchema<any, any>>(state: DatabaseState, schema: S, tableName: string, values: KRecord[]): [DatabaseState, KRecord[]] => {\r\n  const oldTableState = state[tableName];\r\n  if (!oldTableState) throw KonroError(`Table \"${tableName}\" does not exist in the database state.`);\r\n\r\n  // To maintain immutability, we deep-clone only the table being modified.\r\n  const tableState = structuredClone(oldTableState);\r\n  const tableSchema = schema.tables[tableName];\r\n  if (!tableSchema) throw KonroError(`Schema for table \"${tableName}\" not found.`);\r\n  const insertedRecords: KRecord[] = [];\r\n\r\n  for (const value of values) {\r\n    const newRecord: KRecord = { ...value };\r\n    // Handle IDs and defaults\r\n    for (const colName in tableSchema) {\r\n      const colDef = tableSchema[colName];\r\n      if (colDef.dataType === 'id') {\r\n        if (newRecord[colName] === undefined) {\r\n          // Generate new PK if not provided\r\n          if (colDef.options?._pk_strategy === 'uuid') {\r\n            newRecord[colName] = randomUUID();\r\n          } else { // 'auto-increment' or legacy undefined strategy\r\n            tableState.meta.lastId++;\r\n            newRecord[colName] = tableState.meta.lastId;\r\n          }\r\n        } else {\r\n          // If user provided an ID for an auto-increment table, update lastId to avoid future collisions.\r\n          if (colDef.options?._pk_strategy !== 'uuid' && typeof newRecord[colName] === 'number') {\r\n            tableState.meta.lastId = Math.max(tableState.meta.lastId, newRecord[colName] as number);\r\n          }\r\n        }\r\n      }\r\n      if (newRecord[colName] === undefined && colDef.options?.default !== undefined) {\r\n        newRecord[colName] = typeof colDef.options.default === 'function' ? colDef.options.default() : colDef.options.default;\r\n      }\r\n    }\r\n\r\n    // Validate the record before inserting\r\n    validateRecord(newRecord, tableSchema, tableState.records);\r\n\r\n    tableState.records.push(newRecord);\r\n    insertedRecords.push(newRecord);\r\n  }\r\n\r\n  const newState = { ...state, [tableName]: tableState };\r\n  return [newState, insertedRecords];\r\n};\r\n\r\n// --- UPDATE ---\r\n\r\nexport const _updateImpl = <S extends KonroSchema<any, any>>(state: DatabaseState, schema: S, tableName: string, data: Partial<KRecord>, predicate: (record: KRecord) => boolean): [DatabaseState, KRecord[]] => {\r\n  const oldTableState = state[tableName];\r\n  if (!oldTableState) throw KonroError(`Table \"${tableName}\" does not exist in the database state.`);\r\n\r\n  const tableSchema = schema.tables[tableName];\r\n  if (!tableSchema) {\r\n    throw KonroError(`Schema for table \"${tableName}\" not found.`);\r\n  }\r\n\r\n  const updatedRecords: KRecord[] = [];\r\n\r\n  // Auto-update 'updatedAt' timestamp\r\n  for (const colName of Object.keys(tableSchema)) {\r\n      if (tableSchema[colName]?.options?._konro_sub_type === 'updatedAt') {\r\n          (data as KRecord)[colName] = new Date();\r\n      }\r\n  }\r\n\r\n  const updateData = { ...data };\r\n  // Find the ID column from the schema and prevent it from being updated.\r\n  const idColumn = Object.entries(tableSchema).find(([, colDef]) => {\r\n    return colDef && typeof colDef === 'object' && '_type' in colDef && colDef._type === 'column' && 'dataType' in colDef && colDef.dataType === 'id';\r\n  })?.[0];\r\n  if (idColumn && updateData[idColumn] !== undefined) {\r\n    delete updateData[idColumn];\r\n  }\r\n\r\n  const newRecords = oldTableState.records.map(record => {\r\n    if (predicate(record)) {\r\n      const updatedRecord = { ...record, ...updateData };\r\n\r\n      // Validate the updated record, excluding current record from unique checks\r\n      const otherRecords = oldTableState.records.filter(r => r !== record);\r\n      validateRecord(updatedRecord, tableSchema, otherRecords);\r\n\r\n      updatedRecords.push(updatedRecord);\r\n      return updatedRecord;\r\n    }\r\n    return record;\r\n  });\r\n\r\n  if (updatedRecords.length === 0) {\r\n    return [state, []];\r\n  }\r\n\r\n  const tableState = { ...oldTableState, records: newRecords };\r\n  const newState = { ...state, [tableName]: tableState };\r\n\r\n  return [newState, updatedRecords];\r\n};\r\n\r\n\r\n// --- DELETE ---\r\n\r\nfunction applyCascades<S extends KonroSchema<any, any>>(\r\n  state: DatabaseState<S>,\r\n  schema: S,\r\n  tableName: string,\r\n  deletedRecords: KRecord[]\r\n): DatabaseState<S> {\r\n  if (deletedRecords.length === 0) {\r\n    return state;\r\n  }\r\n\r\n  let nextState = state;\r\n  const relations = schema.relations[tableName] ?? {};\r\n\r\n  for (const relationName in relations) {\r\n    const relationDef = relations[relationName];\r\n    // We only cascade from the \"one\" side of a one-to-many relationship, which is a 'many' type in Konro.\r\n    if (!relationDef || relationDef.relationType !== 'many' || !relationDef.onDelete) {\r\n      continue;\r\n    }\r\n\r\n    const sourceKey = relationDef.on;\r\n    const targetTable = relationDef.targetTable;\r\n    const targetKey = relationDef.references;\r\n\r\n    const sourceKeyValues = deletedRecords.map(r => r[sourceKey]).filter(v => v !== undefined);\r\n    if (sourceKeyValues.length === 0) continue;\r\n\r\n    const sourceKeySet = new Set(sourceKeyValues);\r\n    const predicate = (record: KRecord) => sourceKeySet.has(record[targetKey] as any);\r\n\r\n    if (relationDef.onDelete === 'CASCADE') {\r\n      // Recursively delete\r\n      const [newState, ] = _deleteImpl(nextState, schema, targetTable, predicate);\r\n      nextState = newState as DatabaseState<S>;\r\n    } else if (relationDef.onDelete === 'SET NULL') {\r\n      // Update FK to null\r\n      const [newState, ] = _updateImpl(nextState, schema, targetTable, { [targetKey]: null }, predicate);\r\n      nextState = newState as DatabaseState<S>;\r\n    }\r\n  }\r\n\r\n  return nextState;\r\n}\r\n\r\nexport const _deleteImpl = (state: DatabaseState, schema: KonroSchema<any, any>, tableName: string, predicate: (record: KRecord) => boolean): [DatabaseState, KRecord[]] => {\r\n  const oldTableState = state[tableName];\r\n  if (!oldTableState) throw KonroError(`Table \"${tableName}\" does not exist in the database state.`);\r\n  const tableSchema = schema.tables[tableName];\r\n  if (!tableSchema) throw KonroError(`Schema for table \"${tableName}\" not found.`);\r\n\r\n  const deletedAtColumn = Object.keys(tableSchema).find(key => tableSchema[key]?.options?._konro_sub_type === 'deletedAt');\r\n\r\n  // Soft delete path\r\n  if (deletedAtColumn) {\r\n    const recordsToUpdate: KRecord[] = [];\r\n    const now = new Date();\r\n\r\n    const newRecords = oldTableState.records.map(record => {\r\n      if (!record[deletedAtColumn] && predicate(record)) { // Not already soft-deleted and matches predicate\r\n        const updatedRecord = { ...record, [deletedAtColumn]: now };\r\n        recordsToUpdate.push(updatedRecord);\r\n        return updatedRecord;\r\n      }\r\n      return record;\r\n    });\r\n\r\n    if (recordsToUpdate.length === 0) return [state, []];\r\n\r\n    const baseState = { ...state, [tableName]: { ...oldTableState, records: newRecords } };\r\n    const finalState = applyCascades(baseState, schema, tableName, recordsToUpdate);\r\n    \r\n    // The returned records are the ones that were just soft-deleted from this table.\r\n    return [finalState, recordsToUpdate];\r\n  } \r\n  \r\n  // Hard delete path\r\n  const recordsToDelete: KRecord[] = [];\r\n  const keptRecords = oldTableState.records.filter(r => predicate(r) ? (recordsToDelete.push(r), false) : true);\r\n\r\n  if (recordsToDelete.length === 0) return [state, []];\r\n\r\n  const baseState = { ...state, [tableName]: { ...oldTableState, records: keptRecords } };\r\n  const finalState = applyCascades(baseState, schema, tableName, recordsToDelete);\r\n\r\n  return [finalState, recordsToDelete];\r\n};\r\n\r\n// --- VALIDATION ---\r\n\r\nconst validateRecord = (record: KRecord, tableSchema: Record<string, any>, existingRecords: KRecord[]): void => {\r\n  for (const [columnName, colDef] of Object.entries(tableSchema)) {\r\n    if (!colDef || typeof colDef !== 'object' || !('dataType' in colDef)) continue;\r\n\r\n    const value = record[columnName];\r\n    const options = colDef.options || {};\r\n\r\n    // Skip validation for undefined values (they should have defaults applied already)\r\n    if (value === undefined) continue;\r\n\r\n    // Validate unique constraint\r\n    if (options.unique && existingRecords.some(r => r[columnName] === value)) {\r\n      throw KonroValidationError(`Value '${String(value)}' for column '${columnName}' must be unique`);\r\n    }\r\n\r\n    // Validate string constraints\r\n    if (colDef.dataType === 'string' && typeof value === 'string') {\r\n      // Min length\r\n      if (options.min !== undefined && value.length < options.min) {\r\n        throw KonroValidationError(`String '${value}' for column '${columnName}' is too short (min: ${options.min})`);\r\n      }\r\n\r\n      // Max length\r\n      if (options.max !== undefined && value.length > options.max) {\r\n        throw KonroValidationError(`String '${value}' for column '${columnName}' is too long (max: ${options.max})`);\r\n      }\r\n\r\n      // Format validation\r\n      if (options.format === 'email' && !isValidEmail(value)) {\r\n        throw KonroValidationError(`Value '${value}' for column '${columnName}' is not a valid email`);\r\n      }\r\n    }\r\n\r\n    // Validate number constraints\r\n    if (colDef.dataType === 'number' && typeof value === 'number') {\r\n      // Min value\r\n      if (options.min !== undefined && value < options.min) {\r\n        throw KonroValidationError(`Number ${value} for column '${columnName}' is too small (min: ${options.min})`);\r\n      }\r\n\r\n      // Max value\r\n      if (options.max !== undefined && value > options.max) {\r\n        throw KonroValidationError(`Number ${value} for column '${columnName}' is too large (max: ${options.max})`);\r\n      }\r\n    }\r\n  }\r\n};\r\n\r\nconst isValidEmail = (email: string): boolean => {\r\n  const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\r\n  return emailRegex.test(email);\r\n};"
  src/db.ts: >-
    import path from 'path';

    import { AggregationDefinition, ColumnDefinition, KonroSchema,
    RelationDefinition } from './schema';

    import { StorageAdapter, FileStorageAdapter } from './adapter';

    import { DatabaseState, KRecord, TableState } from './types';

    import { _queryImpl, _insertImpl, _updateImpl, _deleteImpl, createEmptyState
    as createEmptyStateImpl, QueryDescriptor, _aggregateImpl,
    AggregationDescriptor } from './operations';

    import { createPredicateFromPartial } from './utils/predicate.util';

    import { KonroError, KonroStorageError } from './utils/error.util';

    import { writeAtomic } from './fs';


    // A helper to normalize a predicate argument

    const normalizePredicate = <T extends KRecord>(
      predicate: Partial<T> | ((record: T) => boolean)
    ): ((record: KRecord) => boolean) =>
      // The cast is necessary due to function argument contravariance.
      // The internal operations work on the wider `KRecord`, while the fluent API provides the specific `T`.
      (typeof predicate === 'function' ? predicate : createPredicateFromPartial(predicate)) as (record: KRecord) => boolean;

    // --- TYPE HELPERS for Fluent API ---


    type RelatedModel<T> = T extends (infer R)[] ? R : T extends (infer R |
    null) ? R : T;


    // TAll is the full relational model type, e.g. schema.types.users

    type WithArgument<TAll> = { // e.g. TAll = S['types']['users']
      [K in keyof TAll as NonNullable<TAll[K]> extends any[] | object ? K : never]?: boolean | ({
        where?: (record: RelatedModel<NonNullable<TAll[K]>>) => boolean;
      } & (
        | { select: Record<string, ColumnDefinition<unknown>>; with?: never }
        | { select?: never; with?: WithArgument<RelatedModel<NonNullable<TAll[K]>>> }
      ));
    };


    type ResolveWith<
      S extends KonroSchema<any, any>,
      TName extends keyof S['tables'],
      TWith extends WithArgument<S['types'][TName]>
    > = { // TName='users', TWith={posts: {with: {author: true}}}
        [K in keyof TWith & keyof S['relations'][TName]]:
            S['relations'][TName][K] extends { relationType: 'many' }
                ? ( // 'many' relation -> array result. K = 'posts'
                    TWith[K] extends { select: infer TSelect }
                        ? ({ [P in keyof TSelect]: InferColumnType<TSelect[P]> })[]
                        : TWith[K] extends { with: infer TNestedWith }
                            // S['relations']['users']['posts']['targetTable'] = 'posts'
                            ? (S['base'][S['relations'][TName][K]['targetTable']] & ResolveWith<S, S['relations'][TName][K]['targetTable'], TNestedWith & WithArgument<S['types'][S['relations'][TName][K]['targetTable']]>>)[]
                            // posts: true.
                            : S['base'][S['relations'][TName][K]['targetTable']][]
                  )
                : S['relations'][TName][K] extends { relationType: 'one' }
                    ? ( // 'one' relation -> nullable object result
                        TWith[K] extends { select: infer TSelect }
                            ? ({ [P in keyof TSelect]: InferColumnType<TSelect[P]> }) | null
                            : TWith[K] extends { with: infer TNestedWith }
                                ? (S['base'][S['relations'][TName][K]['targetTable']] & ResolveWith<S, S['relations'][TName][K]['targetTable'], TNestedWith & WithArgument<S['types'][S['relations'][TName][K]['targetTable']]>>) | null
                                : S['base'][S['relations'][TName][K]['targetTable']] | null
                      )
                    : never
    };


    // InferColumnType is not exported from schema, so we need it here too.

    type InferColumnType<C> = C extends ColumnDefinition<infer T> ? T : never;


    // --- IN-MEMORY API TYPES (STATEFUL) ---


    interface ChainedQueryBuilder<S extends KonroSchema<any, any>, TName extends
    keyof S['tables'], TReturn> {
      select(fields: Record<string, ColumnDefinition<unknown> | RelationDefinition>): this;
      where(predicate: Partial<S['base'][TName]> | ((record: S['base'][TName]) => boolean)): this;
      withDeleted(): this;
      with<W extends WithArgument<S['types'][TName]>>(relations: W): ChainedQueryBuilder<S, TName, TReturn & ResolveWith<S, TName, W>>;
      limit(count: number): this;
      offset(count: number): this;
      all(): TReturn[];
      first(): TReturn | null;
      aggregate<TAggs extends Record<string, AggregationDefinition>>(
        aggregations: TAggs
      ): { [K in keyof TAggs]: number | null };
    }


    interface QueryBuilder<S extends KonroSchema<any, any>> {
      from<T extends keyof S['tables']>(tableName: T): ChainedQueryBuilder<S, T, S['base'][T]>;
    }


    interface UpdateBuilder<S extends KonroSchema<any, any>, TBase, TCreate> {
      set(data: Partial<TCreate>): {
        where(predicate: Partial<TBase> | ((record: TBase) => boolean)): [DatabaseState<S>, TBase[]];
      };
    }


    interface DeleteBuilder<S extends KonroSchema<any, any>, TBase> {
      where(predicate: Partial<TBase> | ((record: TBase) => boolean)): [DatabaseState<S>, TBase[]];
    }


    export interface InMemoryDbContext<S extends KonroSchema<any, any>> {
      schema: S;
      adapter: StorageAdapter;
      read(): Promise<DatabaseState<S>>;
      write(state: DatabaseState<S>): Promise<void>;
      createEmptyState(): DatabaseState<S>;

      query(state: DatabaseState<S>): QueryBuilder<S>;
      insert<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T, values: S['create'][T]): [DatabaseState<S>, S['base'][T]];
      insert<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T, values: Readonly<S['create'][T]>[]): [DatabaseState<S>, S['base'][T][]];
      update<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): UpdateBuilder<S, S['base'][T], S['create'][T]>;
      delete<T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): DeleteBuilder<S, S['base'][T]>;
    }



    // --- ON-DEMAND API TYPES (STATELESS & ASYNC) ---


    interface OnDemandChainedQueryBuilder<S extends KonroSchema<any, any>, TName
    extends keyof S['tables'], TReturn> {
      select(fields: Record<string, ColumnDefinition<unknown> | RelationDefinition>): this;
      where(predicate: Partial<S['base'][TName]> | ((record: S['base'][TName]) => boolean)): this;
      withDeleted(): this;
      with<W extends WithArgument<S['types'][TName]>>(relations: W): OnDemandChainedQueryBuilder<S, TName, TReturn & ResolveWith<S, TName, W>>;
      limit(count: number): this;
      offset(count: number): this;
      all(): Promise<TReturn[]>;
      first(): Promise<TReturn | null>;
      aggregate<TAggs extends Record<string, AggregationDefinition>>(
        aggregations: TAggs
      ): Promise<{ [K in keyof TAggs]: number | null }>;
    }


    interface OnDemandQueryBuilder<S extends KonroSchema<any, any>> {
      from<T extends keyof S['tables']>(tableName: T): OnDemandChainedQueryBuilder<S, T, S['base'][T]>;
    }


    interface OnDemandUpdateBuilder<TBase, TCreate> {
      set(data: Partial<TCreate>): {
        where(predicate: Partial<TBase> | ((record: TBase) => boolean)): Promise<TBase[]>;
      };
    }


    interface OnDemandDeleteBuilder<TBase> {
      where(predicate: Partial<TBase> | ((record: TBase) => boolean)): Promise<TBase[]>;
    }


    export interface OnDemandDbContext<S extends KonroSchema<any, any>> {
      schema: S;
      adapter: StorageAdapter;
      read(): Promise<never>; // Not supported in on-demand mode
      write(): Promise<never>; // Not supported in on-demand mode
      createEmptyState(): DatabaseState<S>;

      query(): OnDemandQueryBuilder<S>;
      insert<T extends keyof S['tables']>(tableName: T, values: S['create'][T]): Promise<S['base'][T]>;
      insert<T extends keyof S['tables']>(tableName: T, values: Readonly<S['create'][T]>[]): Promise<S['base'][T][]>;
      update<T extends keyof S['tables']>(tableName: T): OnDemandUpdateBuilder<S['base'][T], S['create'][T]>;
      delete<T extends keyof S['tables']>(tableName: T): OnDemandDeleteBuilder<S['base'][T]>;
    }


    // --- DbContext Union Type ---

    export type DbContext<S extends KonroSchema<any, any>> =
    InMemoryDbContext<S> | OnDemandDbContext<S>;


    // --- CORE LOGIC (STATELESS & PURE) ---


    /**
     * Creates the core, stateless database operations.
     * These operations are pure functions that take a database state and return a new state,
     * forming the foundation for both in-memory and on-demand modes.
     */
    function createCoreDbContext<S extends KonroSchema<any, any>>(schema: S) {
      const query = (state: DatabaseState<S>): QueryBuilder<S> => ({
        from: <TName extends keyof S['tables']>(tableName: TName): ChainedQueryBuilder<S, TName, S['base'][TName]> => {
          const createBuilder = <TReturn>(currentDescriptor: QueryDescriptor): ChainedQueryBuilder<S, TName, TReturn> => ({
            select(fields) { return createBuilder<TReturn>({ ...currentDescriptor, select: fields }); },
            where(predicate) { return createBuilder<TReturn>({ ...currentDescriptor, where: normalizePredicate(predicate as any) }); },
            withDeleted() { return createBuilder<TReturn>({ ...currentDescriptor, withDeleted: true }); },
            with<W extends WithArgument<S['types'][TName]>>(relations: W) {
              const newWith = { ...currentDescriptor.with, ...(relations as QueryDescriptor['with']) };
              return createBuilder<TReturn & ResolveWith<S, TName, W>>({ ...currentDescriptor, with: newWith });
            },
            limit(count) { return createBuilder<TReturn>({ ...currentDescriptor, limit: count }); },
            offset(count) { return createBuilder<TReturn>({ ...currentDescriptor, offset: count }); },
            all: (): TReturn[] => _queryImpl(state as DatabaseState, schema, currentDescriptor) as any,
            first: (): TReturn | null => (_queryImpl(state as DatabaseState, schema, { ...currentDescriptor, limit: 1 })[0] ?? null) as any,
            aggregate: (aggregations) => {
              const aggDescriptor: AggregationDescriptor = { ...currentDescriptor, aggregations };
              return _aggregateImpl(state as DatabaseState, schema, aggDescriptor) as any;
            },
          });
          return createBuilder<S['base'][TName]>({ tableName: tableName as string });
        },
      });

      const insert = <T extends keyof S['tables']>(
        state: DatabaseState<S>, tableName: T, values: S['create'][T] | Readonly<S['create'][T]>[]
      ): [DatabaseState<S>, S['base'][T] | S['base'][T][]] => {
        const valsArray = Array.isArray(values) ? values : [values];
        const [newState, inserted] = _insertImpl(state as DatabaseState, schema, tableName as string, valsArray as KRecord[]);
        const result = Array.isArray(values) ? inserted : inserted[0];
        return [newState as DatabaseState<S>, result] as [DatabaseState<S>, S['base'][T] | S['base'][T][]];
      };

      const update = <T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): UpdateBuilder<S, S['base'][T], S['create'][T]> => ({
        set: (data) => ({
          where: (predicate) => {
            const [newState, updatedRecords] = _updateImpl(state as DatabaseState, schema, tableName as string, data as Partial<KRecord>, normalizePredicate(predicate as any));
            return [newState as DatabaseState<S>, updatedRecords as S['base'][T][]];
          },
        }),
      });

      const del = <T extends keyof S['tables']>(state: DatabaseState<S>, tableName: T): DeleteBuilder<S, S['base'][T]> => ({
        where: (predicate) => {
          const [newState, deletedRecords] = _deleteImpl(state as DatabaseState, schema, tableName as string, normalizePredicate(predicate as any));
          return [newState as DatabaseState<S>, deletedRecords as S['base'][T][]];
        },
      });

      return { query, insert, update, delete: del };
    }


    // --- ON-DEMAND CONTEXT (STATEFUL WRAPPER) ---


    function createMultiFileOnDemandDbContext<S extends KonroSchema<any, any>>(
      schema: S,
      adapter: FileStorageAdapter,
      core: ReturnType<typeof createCoreDbContext<S>>
    ): OnDemandDbContext<S> {
      const { dir } = adapter.options.multi!;

      const readTableState = async (tableName: string): Promise<TableState> => {
        const filepath = path.join(dir, `${tableName}${adapter.fileExtension}`);
        const data = await adapter.fs.readFile(filepath);
        if (!data) return { records: [], meta: { lastId: 0 } };
        try {
          return adapter.serializer.parse(data, schema.tables[tableName]);
        } catch (e: any) {
          throw KonroStorageError(`Failed to parse file at "${filepath}". It may be corrupt or not a valid ${adapter.options.format} file. Original error: ${e.message}`);
        }
      };

      const writeTableState = async (tableName: string, tableState: TableState): Promise<void> => {
        await adapter.fs.mkdir(dir, { recursive: true });
        const filepath = path.join(dir, `${tableName}${adapter.fileExtension}`);
        const content = adapter.serializer.stringify(tableState);
        await writeAtomic(filepath, content, adapter.fs);
      };
      
      // For queries with relations, we need the full state.
      const getFullState = async (): Promise<DatabaseState<S>> => {
        const state = createEmptyStateImpl(schema);
        await Promise.all(Object.keys(schema.tables).map(async (tableName) => {
          (state as any)[tableName] = await readTableState(tableName);
        }));
        return state;
      }

      // A generic handler for CUD operations that reads one table, performs an action, and writes it back.
      const performCud = async <TResult>(tableName: string, action: (state: DatabaseState<S>) => [DatabaseState<S>, TResult]): Promise<TResult> => {
        const state = createEmptyStateImpl(schema);
        (state as any)[tableName] = await readTableState(tableName);
        const [newState, result] = action(state as DatabaseState<S>);
        
        // Check if the operation produced a result (e.g., an array of inserted/updated/deleted records)
        const hasChanges = Array.isArray(result) ? result.length > 0 : result !== null;
        if (hasChanges) {
          const newTableState = newState[tableName as string];
          // This check satisfies the `noUncheckedIndexedAccess` compiler option.
          // Our CUD logic ensures this state will always exist after a change.
          if (newTableState) {
            await writeTableState(tableName, newTableState);
          }
        }
        return result;
      };

      const query = (): OnDemandQueryBuilder<S> => ({
        from: <TName extends keyof S['tables']>(tableName: TName): OnDemandChainedQueryBuilder<S, TName, S['base'][TName]> => {
          // The query builder for on-demand must be separate because its terminal methods are async.
          const createBuilder = <TReturn>(currentDescriptor: QueryDescriptor): OnDemandChainedQueryBuilder<S, TName, TReturn> => ({
            select(fields) { return createBuilder<TReturn>({ ...currentDescriptor, select: fields }); },
            where(predicate) { return createBuilder<TReturn>({ ...currentDescriptor, where: normalizePredicate(predicate as any) }); },
            withDeleted() { return createBuilder<TReturn>({ ...currentDescriptor, withDeleted: true }); },
            with<W extends WithArgument<S['types'][TName]>>(relations: W) {
              const newWith = { ...currentDescriptor.with, ...(relations as QueryDescriptor['with']) };
              return createBuilder<TReturn & ResolveWith<S, TName, W>>({ ...currentDescriptor, with: newWith });
            },
            limit(count) { return createBuilder<TReturn>({ ...currentDescriptor, limit: count }); },
            offset(count) { return createBuilder<TReturn>({ ...currentDescriptor, offset: count }); },
            all: async (): Promise<TReturn[]> => {
              const state = await getFullState();
              return _queryImpl(state, schema, currentDescriptor) as any;
            },
            first: async (): Promise<TReturn | null> => {
              const state = await getFullState();
              return (_queryImpl(state, schema, { ...currentDescriptor, limit: 1 })[0] ?? null) as any;
            },
            aggregate: async (aggregations) => {
              const state = await getFullState();
              const aggDescriptor: AggregationDescriptor = { ...currentDescriptor, aggregations };
              return _aggregateImpl(state, schema, aggDescriptor) as any;
            },
          });
          return createBuilder<S['base'][TName]>({ tableName: tableName as string });
        },
      });

      const insert = <T extends keyof S['tables']>(tableName: T, values: S['create'][T] | Readonly<S['create'][T]>[]): Promise<any> => 
        performCud(tableName as string, (state) => core.insert(state, tableName, values as any));

      const update = <T extends keyof S['tables']>(tableName: T): OnDemandUpdateBuilder<S['base'][T], S['create'][T]> => ({
        set: (data) => ({
          where: (predicate) => performCud(tableName as string, (state) => core.update(state, tableName).set(data).where(predicate as any)) as Promise<S['base'][T][]>,
        }),
      });

      const del = <T extends keyof S['tables']>(tableName: T): OnDemandDeleteBuilder<S['base'][T]> => ({
        where: async (predicate) => {
          // Cascading deletes require the full state.
          const state = await getFullState();
          const [newState, deletedRecords] = core.delete(state, tableName).where(predicate as any);

          // Find changed tables and write them back
          const changedTableNames = Object.keys(newState).filter(key => newState[key as keyof typeof newState] !== state[key as keyof typeof state]);
          
          await Promise.all(
            changedTableNames.map(name => writeTableState(name, newState[name as keyof typeof newState]!))
          );

          return deletedRecords as S['base'][T][];
        },
      });

      const notSupported = () => Promise.reject(KonroError("This method is not supported in 'on-demand' mode."));

      return {
        schema,
        adapter,
        read: notSupported,
        write: notSupported,
        createEmptyState: () => createEmptyStateImpl(schema),
        query,
        insert,
        update,
        delete: del,
      };
    }


    function createPerRecordOnDemandDbContext<S extends KonroSchema<any, any>>(
      schema: S,
      adapter: FileStorageAdapter,
      core: ReturnType<typeof createCoreDbContext<S>>
    ): OnDemandDbContext<S> {
      const { dir } = adapter.options.perRecord!;
      const { fs, serializer, fileExtension } = adapter;

      const getTableDir = (tableName: string) => path.join(dir, tableName);
      const getRecordPath = (tableName: string, recordId: string | number) => path.join(getTableDir(tableName), `${recordId}${fileExtension}`);
      const getMetaPath = (tableName: string) => path.join(getTableDir(tableName), '_meta.json');

      const getIdColumn = (tableName: string) => {
        const tableSchema = schema.tables[tableName];
        const idColumn = Object.keys(tableSchema).find((key) => tableSchema[key]?.dataType === 'id');
        if (!idColumn) {
          throw KonroError(`Table "${tableName}" must have an 'id' column to be used with 'per-record' storage.`);
        }
        return idColumn;
      };

      const readMeta = async (tableName: string): Promise<{ lastId: number }> => {
        const metaContent = await fs.readFile(getMetaPath(tableName));
        return metaContent ? JSON.parse(metaContent) : { lastId: 0 };
      };

      const writeMeta = async (tableName: string, meta: { lastId: number }): Promise<void> => {
        await fs.mkdir(getTableDir(tableName), { recursive: true });
        await writeAtomic(getMetaPath(tableName), JSON.stringify(meta, null, 2), fs);
      };

      const readTableState = async (tableName: string): Promise<TableState> => {
        const tableDir = getTableDir(tableName);
        await fs.mkdir(tableDir, { recursive: true });

        const meta = await readMeta(tableName);
        const files = await fs.readdir(tableDir);
        const recordFiles = files.filter((f) => !f.startsWith('_meta'));

        const records = (
          await Promise.all(
            recordFiles.map(async (file) => {
              const content = await fs.readFile(path.join(tableDir, file));
              return content ? serializer.parse<KRecord>(content) : null;
            })
          )
        ).filter((r): r is KRecord => r !== null);

        return { records, meta };
      };

      const getFullState = async (): Promise<DatabaseState<S>> => {
        const state = createEmptyStateImpl(schema);
        await Promise.all(
          Object.keys(schema.tables).map(async (tableName) => {
            (state as any)[tableName] = await readTableState(tableName);
          })
        );
        return state;
      };

      const query = (): OnDemandQueryBuilder<S> => ({
        from: <TName extends keyof S['tables']>(tableName: TName): OnDemandChainedQueryBuilder<S, TName, S['base'][TName]> => {
          const createBuilder = <TReturn>(currentDescriptor: QueryDescriptor): OnDemandChainedQueryBuilder<S, TName, TReturn> => ({
            select(fields) { return createBuilder<TReturn>({ ...currentDescriptor, select: fields }); },
            where(predicate) { return createBuilder<TReturn>({ ...currentDescriptor, where: normalizePredicate(predicate as any) }); },
            withDeleted() { return createBuilder<TReturn>({ ...currentDescriptor, withDeleted: true }); },
            with<W extends WithArgument<S['types'][TName]>>(relations: W) {
              const newWith = { ...currentDescriptor.with, ...(relations as QueryDescriptor['with']) };
              return createBuilder<TReturn & ResolveWith<S, TName, W>>({ ...currentDescriptor, with: newWith });
            },
            limit(count) { return createBuilder<TReturn>({ ...currentDescriptor, limit: count }); },
            offset(count) { return createBuilder<TReturn>({ ...currentDescriptor, offset: count }); },
            all: async (): Promise<TReturn[]> => {
              const state = await getFullState();
              return _queryImpl(state, schema, currentDescriptor) as any;
            },
            first: async (): Promise<TReturn | null> => {
              const state = await getFullState();
              return (_queryImpl(state, schema, { ...currentDescriptor, limit: 1 })[0] ?? null) as any;
            },
            aggregate: async (aggregations) => {
              const state = await getFullState();
              const aggDescriptor: AggregationDescriptor = { ...currentDescriptor, aggregations };
              return _aggregateImpl(state, schema, aggDescriptor) as any;
            },
          });
          return createBuilder<S['base'][TName]>({ tableName: tableName as string });
        },
      });

      const insert = async <T extends keyof S['tables']>(tableName: T, values: S['create'][T] | Readonly<S['create'][T]>[]): Promise<any> => {
        const tableNameStr = tableName as string;
        const meta = await readMeta(tableNameStr);
        const idColumn = getIdColumn(tableNameStr);

        // We only need a shallow table state for insert, no records needed for validation context.
        const tempState: DatabaseState = { [tableNameStr]: { records: [], meta } };
        const [newState, insertedResult] = core.insert(tempState as any, tableName, values as any);

        const insertedAsArray = Array.isArray(insertedResult) ? insertedResult : insertedResult ? [insertedResult] : [];

        if (insertedAsArray.length === 0) {
          return insertedResult; // Return original empty array or null
        }

        await Promise.all(
          (insertedAsArray as KRecord[]).map((rec) => {
            const recordPath = getRecordPath(tableNameStr, rec[idColumn] as any);
            return writeAtomic(recordPath, serializer.stringify(rec), fs);
          })
        );

        const newMeta = (newState as DatabaseState)[tableNameStr]?.meta;
        if (newMeta && newMeta.lastId !== meta.lastId) {
          await writeMeta(tableNameStr, newMeta);
        }

        return insertedResult;
      };

      const update = <T extends keyof S['tables']>(tableName: T): OnDemandUpdateBuilder<S['base'][T], S['create'][T]> => ({
        set: (data) => ({
          where: async (predicate) => {
            const tableNameStr = tableName as string;
            const tableState = await readTableState(tableNameStr);
            const idColumn = getIdColumn(tableNameStr);
            const [, updatedRecords] = core.update({ [tableNameStr]: tableState } as any, tableName).set(data).where(predicate as any);

            if (updatedRecords.length > 0) {
              await Promise.all(
                (updatedRecords as KRecord[]).map((rec) => writeAtomic(getRecordPath(tableNameStr, rec[idColumn] as any), serializer.stringify(rec), fs))
              );
            }
            return updatedRecords as S['base'][T][];
          },
        }),
      });

      const del = <T extends keyof S['tables']>(tableName: T): OnDemandDeleteBuilder<S['base'][T]> => ({
        where: async (predicate) => {
          const state = await getFullState();
          const [newState, deletedRecords] = core.delete(state, tableName).where(predicate as any);

          const changePromises: Promise<any>[] = [];

          for (const tName of Object.keys(schema.tables)) {
            const oldTableState = state[tName as keyof typeof state]!;
            const newTableState = newState[tName as keyof typeof newState]!;

            if (oldTableState === newTableState) continue;

            const tableDir = getTableDir(tName);
            changePromises.push(fs.mkdir(tableDir, { recursive: true }));

            if (JSON.stringify(oldTableState.meta) !== JSON.stringify(newTableState.meta)) {
              changePromises.push(writeMeta(tName, newTableState.meta));
            }

            const tIdColumn = getIdColumn(tName);
            const oldRecordsMap = new Map(oldTableState.records.map(r => [r[tIdColumn], r]));
            const newRecordsMap = new Map(newTableState.records.map(r => [r[tIdColumn], r]));
            
            for (const [id, record] of newRecordsMap.entries()) {
                const oldRecord = oldRecordsMap.get(id);
                // Write if new or record object identity has changed
                if (!oldRecord || oldRecord !== record) {
                    changePromises.push(writeAtomic(getRecordPath(tName, id as any), serializer.stringify(record), fs));
                }
            }
            
            for (const id of oldRecordsMap.keys()) {
                if (!newRecordsMap.has(id)) { // Deleted record
                    changePromises.push(fs.unlink(getRecordPath(tName, id as any)));
                }
            }
          }

          await Promise.all(changePromises);

          return deletedRecords as S['base'][T][];
        },
      });

      const notSupported = () => Promise.reject(KonroError("This method is not supported in 'on-demand' mode."));

      return { schema, adapter, createEmptyState: () => createEmptyStateImpl(schema), read: notSupported, write: notSupported, query, insert, update, delete: del };
    }



    // --- DATABASE FACTORY ---


    export function createDatabase<
      S extends KonroSchema<any, any>,
      TAdapter extends StorageAdapter,
    >(
      options: { schema: S; adapter: TAdapter }
    ): TAdapter['mode'] extends 'on-demand' ? OnDemandDbContext<S> :
    InMemoryDbContext<S>;

    export function createDatabase<S extends KonroSchema<any, any>>(
      options: { schema: S; adapter: StorageAdapter }
    ): DbContext<S> {
      const { schema, adapter } = options;
      const core = createCoreDbContext(schema);

      if (adapter.mode === 'on-demand') {
        const fileAdapter = adapter as FileStorageAdapter; // We can be sure it's a FileStorageAdapter due to checks
        if (fileAdapter.options.multi) {
          return createMultiFileOnDemandDbContext(schema, fileAdapter, core);
        }
        if (fileAdapter.options.perRecord) {
          return createPerRecordOnDemandDbContext(schema, fileAdapter, core);
        }
        throw KonroError("The 'on-demand' mode requires a 'multi-file' or 'per-record' storage strategy.");
      }

      // For in-memory, just combine the core logic with the adapter and I/O methods.
      return {
        ...core,
        schema, adapter,
        read: () => adapter.read(schema),
        write: (state) => adapter.write(state, schema),
        createEmptyState: () => createEmptyStateImpl(schema),
      } as InMemoryDbContext<S>;
    }
  src/adapter.ts: >-
    import path from 'path';

    import type { DatabaseState, KRecord, TableState } from './types';

    import { createEmptyState } from './operations';

    import type { ColumnDefinition, KonroSchema } from './schema';

    import { type Serializer, getSerializer } from './utils/serializer.util';

    import { FsProvider, defaultFsProvider, writeAtomic } from './fs';

    import { KonroError, KonroStorageError } from './utils/error.util';

    import { TEMP_FILE_SUFFIX } from './utils/constants';


    export interface StorageAdapter {
      read<S extends KonroSchema<any, any>>(schema: S): Promise<DatabaseState<S>>;
      write(state: DatabaseState<any>, schema: KonroSchema<any, any>): Promise<void>;
      readonly mode: 'in-memory' | 'on-demand';
    }


    export interface FileStorageAdapter extends StorageAdapter {
      readonly options: FileAdapterOptions;
      readonly fs: FsProvider;
      readonly serializer: Serializer;
      readonly fileExtension: string;
    }


    type SingleFileStrategy = { single: { filepath: string }; multi?: never;
    perRecord?: never };

    type MultiFileStrategy = { multi: { dir: string }; single?: never;
    perRecord?: never };

    type PerRecordStrategy = { perRecord: { dir: string }; single?: never;
    multi?: never };


    export type FileAdapterOptions = {
      format: 'json' | 'yaml' | 'csv' | 'xlsx';
      fs?: FsProvider;
      /**
       * Defines the data access strategy.
       * - `in-memory`: (Default) Loads the entire database into memory on init. Fast for small/medium datasets.
       * - `on-demand`: Reads from the file system for each query. Slower but supports larger datasets. Requires 'multi-file' or 'per-record' strategy.
       */
      mode?: 'in-memory' | 'on-demand';
    } & (SingleFileStrategy | MultiFileStrategy | PerRecordStrategy);


    export function createFileAdapter(options: FileAdapterOptions & { mode:
    'on-demand' }): FileStorageAdapter & { mode: 'on-demand' };

    export function createFileAdapter(options: FileAdapterOptions & { mode?:
    'in-memory' | undefined }): FileStorageAdapter & { mode: 'in-memory' };

    export function createFileAdapter(options: FileAdapterOptions):
    FileStorageAdapter;

    export function createFileAdapter(options: FileAdapterOptions):
    FileStorageAdapter {
      const serializer = getSerializer(options.format);
      const fileExtension = `.${options.format}`;
      const fs = options.fs ?? defaultFsProvider;
      const mode = options.mode ?? 'in-memory';

      if (options.perRecord && options.format !== 'json' && options.format !== 'yaml') {
        throw KonroError(`The 'per-record' strategy only supports 'json' or 'yaml' formats.`);
      }

      const isTabular = options.format === 'csv' || options.format === 'xlsx';
      if (isTabular && (mode !== 'on-demand' || !options.multi)) {
        throw KonroError(`The '${options.format}' format only supports 'on-demand' mode with a 'multi-file' strategy.`);
      }

      if (mode === 'on-demand' && options.single) {
        throw KonroError("The 'on-demand' mode requires the 'multi-file' or 'per-record' storage strategy.");
      }

      const parseFile = async <T>(filepath: string, schema?: Record<string, ColumnDefinition<any>>): Promise<T | undefined> => {
        const data = await fs.readFile(filepath);
        if (!data) return undefined;
        try {
          return serializer.parse<T>(data, schema);
        } catch (e: any) {
          throw KonroStorageError(`Failed to parse file at "${filepath}". It may be corrupt or not a valid ${options.format} file. Original error: ${e.message}`);
        }
      };

      const readSingle = async <S extends KonroSchema<any, any>>(schema: S): Promise<DatabaseState<S>> => {
        const state = await parseFile<DatabaseState<any>>(options.single!.filepath);
        // The cast is acceptable as the original code made the same implicit assumption.
        return (state ?? createEmptyState(schema)) as DatabaseState<S>;
      };

      const readMulti = async <S extends KonroSchema<any, any>>(schema: S): Promise<DatabaseState<S>> => {
        const dir = options.multi!.dir;
        await fs.mkdir(dir, { recursive: true });
        const state = createEmptyState(schema);
        await Promise.all(
          Object.keys(schema.tables).map(async (tableName) => {
            const filepath = path.join(dir, `${tableName}${fileExtension}`);
            const tableState = await parseFile<TableState<any>>(filepath, schema.tables[tableName]);
            if (tableState) (state as any)[tableName] = tableState;
          })
        );
        return state;
      };

      const readPerRecord = async <S extends KonroSchema<any, any>>(schema: S): Promise<DatabaseState<S>> => {
        const dir = options.perRecord!.dir;
        await fs.mkdir(dir, { recursive: true });
        const state = createEmptyState(schema);

        await Promise.all(
          Object.keys(schema.tables).map(async (tableName) => {
            const tableDir = path.join(dir, tableName);
            await fs.mkdir(tableDir, { recursive: true });

            // Read meta file for lastId
            const metaPath = path.join(tableDir, '_meta.json');
            try {
              const metaContent = await fs.readFile(metaPath);
              if (metaContent) {
                (state as any)[tableName].meta = JSON.parse(metaContent);
              }
            } catch (e) {
              /* ignore if not found or parsing fails, will use default */
            }

            const files = await fs.readdir(tableDir);
            const recordFiles = files.filter((f) => !f.startsWith('_meta'));

            const records = await Promise.all(
              recordFiles.map((file) => parseFile<KRecord>(path.join(tableDir, file)))
            );

            (state as any)[tableName].records = records.filter((r): r is KRecord => r != null);

            // If meta file didn't exist or was empty, derive lastId for auto-increment PKs.
            if ((state as any)[tableName].meta.lastId === 0) {
              const tableSchema = schema.tables[tableName];
              const idColumn = Object.keys(tableSchema).find((key) => tableSchema[key]?.dataType === 'id' && tableSchema[key]?.options?._pk_strategy !== 'uuid');
              if (idColumn) {
                (state as any)[tableName].meta.lastId = (state as any)[tableName].records.reduce((maxId: number, record: KRecord) => {
                  const id = record[idColumn];
                  return typeof id === 'number' && id > maxId ? id : maxId;
                }, 0);
              }
            }
          })
        );
        return state;
      };

      const writeSingle = (state: DatabaseState<any>) => writeAtomic(options.single!.filepath, serializer.stringify(state), fs);

      const writeMulti = async (state: DatabaseState<any>) => {
        const dir = options.multi!.dir;
        await fs.mkdir(dir, { recursive: true });
        const writes = Object.entries(state).map(([tableName, tableState]) => {
          const filepath = path.join(dir, `${tableName}${fileExtension}`);
          return writeAtomic(filepath, serializer.stringify(tableState), fs);
        });
        await Promise.all(writes);
      };

      const writePerRecord = async (state: DatabaseState<any>, schema: KonroSchema<any, any>) => {
        const dir = options.perRecord!.dir;
        await fs.mkdir(dir, { recursive: true });

        const writes = Object.entries(state).map(async ([tableName, tableState]) => {
          const tableDir = path.join(dir, tableName);
          await fs.mkdir(tableDir, { recursive: true });

          // Write meta file first
          const metaPath = path.join(tableDir, '_meta.json');
          await writeAtomic(metaPath, JSON.stringify(tableState.meta, null, 2), fs);

          const idColumn = Object.keys(schema.tables[tableName]).find((key) => schema.tables[tableName][key]?.dataType === 'id');
          if (!idColumn) {
            throw KonroError(`Table "${tableName}" must have an 'id' column to be used with 'per-record' storage.`);
          }

          const currentFiles = new Set(tableState.records.map((r: KRecord) => `${r[idColumn]}${fileExtension}`));
          const existingFiles = (await fs.readdir(tableDir)).filter((f) => !f.startsWith('_meta') && !f.endsWith(TEMP_FILE_SUFFIX));

          const recordWrites = tableState.records.map((record: KRecord) => writeAtomic(path.join(tableDir, `${record[idColumn]}${fileExtension}`), serializer.stringify(record), fs));
          const recordsToDelete = existingFiles.filter((f) => !currentFiles.has(f));
          const recordDeletes = recordsToDelete.map((f) => fs.unlink(path.join(tableDir, f)));

          await Promise.all([...recordWrites, ...recordDeletes]);
        });
        await Promise.all(writes);
      };

      return {
        options,
        fs,
        serializer,
        fileExtension,
        mode,
        read: options.single ? readSingle : options.multi ? readMulti : readPerRecord,
        write: options.single ? writeSingle : options.multi ? writeMulti : writePerRecord,
      } as FileStorageAdapter;
    }
approved: true
