uuid: 1dfb8b3d-4c31-4566-a320-13f56372d6f7
projectId: konro
createdAt: '2025-07-09T04:36:38.323Z'
linesAdded: 1
linesRemoved: 1
gitCommitMsg: 'test(adapter): Update on-demand error message in test'
promptSummary: >-
  The user provided a failing test case. The expected error message in the test
  is outdated after a recent feature addition. I am updating the test to expect
  the correct error message.
reasoning:
  - >-
    Of course. The test failed because I updated the error message in the source
    code to include the new `per-record` strategy, but I didn't update the
    corresponding test case.
  - >-
    I'll correct the expected error message in the test to match the new
    implementation.
operations:
  - type: write
    path: test/integration/Adapters/OnDemand.test.ts
    content: >-
      --- test/integration/Adapters/OnDemand.test.ts

      +++ test/integration/Adapters/OnDemand.test.ts

      @@ -40,7 +40,7 @@
                 mode: 'on-demand',
                 single: { filepath: path.join(dbDirPath, 'db.json') },
               });
      -      }).toThrow(KonroError("The 'on-demand' mode requires the
      'multi-file' storage strategy."));

      +      }).toThrow(KonroError("The 'on-demand' mode requires the
      'multi-file' or 'per-record' storage strategy."));
           });
         });
    patchStrategy: new-unified
snapshot:
  test/integration/Adapters/OnDemand.test.ts: "import { describe, it, expect, beforeEach, afterEach } from 'bun:test';\r\nimport { konro } from '../../../src/index';\r\nimport { testSchema, TEST_DIR, cleanup, ensureTestDir, uuidTestSchema } from '../../util';\r\nimport path from 'path';\r\nimport { promises as fs } from 'fs';\r\nimport yaml from 'js-yaml';\r\nimport papaparse from 'papaparse';\nimport xlsx from 'xlsx';\nimport { KonroError } from '../../../src/utils/error.util';\r\nimport type { OnDemandDbContext } from '../../../src/db';\r\n\r\ndescribe('Integration > Adapters > OnDemand', () => {\r\n  const dbDirPath = path.join(TEST_DIR, 'on_demand_db');\r\n\r\n  beforeEach(ensureTestDir);\r\n  afterEach(cleanup);\r\n\r\n  describe('Initialization', () => {\r\n    it('should successfully create an on-demand db context with a multi-file adapter', () => {\r\n      const adapter = konro.createFileAdapter({\r\n        format: 'yaml',\r\n        mode: 'on-demand',\r\n        multi: { dir: dbDirPath },\r\n      });\r\n      const db = konro.createDatabase({\r\n        schema: testSchema,\r\n        adapter,\r\n      });\r\n\r\n      expect(db).toBeDefined();\r\n      expect(db.adapter.mode).toBe('on-demand');\r\n      expect(typeof db.insert).toBe('function');\r\n      expect(typeof db.query).toBe('function');\r\n    });\r\n\r\n    it('should throw an error when creating an on-demand db context with a single-file adapter', () => {\r\n      expect(() => {\r\n        konro.createFileAdapter({\r\n          format: 'json',\r\n          mode: 'on-demand',\r\n          single: { filepath: path.join(dbDirPath, 'db.json') },\r\n        });\r\n      }).toThrow(KonroError(\"The 'on-demand' mode requires the 'multi-file' storage strategy.\"));\r\n    });\r\n  });\r\n\r\n  describe('Unsupported Operations', () => {\r\n    const adapter = konro.createFileAdapter({\r\n      format: 'yaml',\r\n      mode: 'on-demand',\r\n      multi: { dir: dbDirPath },\r\n    });\r\n    const db = konro.createDatabase({\r\n      schema: testSchema,\r\n      adapter,\r\n    });\r\n    \r\n    it('should reject db.read()', async () => {\r\n      expect(db.read()).rejects.toThrow(KonroError(\"This method is not supported in 'on-demand' mode.\"));\r\n    });\r\n\r\n    it('should reject db.write()', async () => {\r\n      expect(db.write()).rejects.toThrow(KonroError(\"This method is not supported in 'on-demand' mode.\"));\r\n    });\r\n  });\r\n\r\n  describe('CRUD Operations', () => {\r\n    let db: OnDemandDbContext<typeof testSchema>;\r\n\r\n    beforeEach(() => {\r\n      const adapter = konro.createFileAdapter({\r\n        format: 'yaml',\r\n        mode: 'on-demand',\r\n        multi: { dir: dbDirPath },\r\n      });\r\n      db = konro.createDatabase({\r\n        schema: testSchema,\r\n        adapter,\r\n      });\r\n    });\r\n\r\n    it('should insert a record and write it to the correct file', async () => {\r\n      const user = await db.insert('users', {\r\n        name: 'OnDemand User',\r\n        email: 'ondemand@test.com',\r\n        age: 25,\r\n      });\r\n\r\n      expect(user.id).toBe(1);\r\n      expect(user.name).toBe('OnDemand User');\r\n\r\n      const userFilePath = path.join(dbDirPath, 'users.yaml');\r\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\r\n      const parsedContent = yaml.load(fileContent) as any;\r\n\r\n      expect(parsedContent.records.length).toBe(1);\r\n      expect(parsedContent.records[0].name).toBe('OnDemand User');\r\n      expect(parsedContent.meta.lastId).toBe(1);\r\n    });\r\n\r\n    it('should query for records', async () => {\r\n      await db.insert('users', { name: 'Query User', email: 'q@test.com', age: 30 });\r\n      \r\n      const user = await db.query().from('users').where({ name: 'Query User' }).first();\r\n      expect(user).toBeDefined();\r\n      expect(user?.name).toBe('Query User');\r\n\r\n      const allUsers = await db.query().from('users').all();\r\n      expect(allUsers.length).toBe(1);\r\n    });\r\n\r\n    it('should update a record', async () => {\r\n      const user = await db.insert('users', { name: 'Update Me', email: 'u@test.com', age: 40 });\r\n      \r\n      const updatedUsers = await db.update('users')\r\n        .set({ name: 'Updated Name' })\r\n        .where({ id: user.id });\r\n\r\n      expect(updatedUsers.length).toBe(1);\r\n      expect(updatedUsers[0]?.name).toBe('Updated Name');\r\n\r\n      const userFilePath = path.join(dbDirPath, 'users.yaml');\r\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\r\n      const parsedContent = yaml.load(fileContent) as any;\r\n      \r\n      expect(parsedContent.records[0].name).toBe('Updated Name');\r\n    });\r\n\r\n    it('should delete a record', async () => {\r\n      const user = await db.insert('users', { name: 'Delete Me', email: 'd@test.com', age: 50 });\r\n      \r\n      await db.delete('users').where({ id: user.id });\r\n\r\n      const users = await db.query().from('users').all();\r\n      expect(users.length).toBe(0);\r\n\r\n      const userFilePath = path.join(dbDirPath, 'users.yaml');\r\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\r\n      const parsedContent = yaml.load(fileContent) as any;\r\n      \r\n      expect(parsedContent.records.length).toBe(0);\r\n    });\r\n    \r\n    it('should query with relations', async () => {\r\n      const user = await db.insert('users', { name: 'Author', email: 'author@test.com', age: 35 });\r\n      await db.insert('posts', { title: 'Post by Author', content: '...', authorId: user.id });\r\n      await db.insert('posts', { title: 'Another Post', content: '...', authorId: user.id });\r\n      \r\n      const userWithPosts = await db.query().from('users').where({ id: user.id }).with({ posts: true }).first();\r\n      \r\n      expect(userWithPosts).toBeDefined();\r\n      expect(userWithPosts?.name).toBe('Author');\r\n      expect(userWithPosts?.posts).toBeInstanceOf(Array);\r\n      expect(userWithPosts?.posts?.length).toBe(2);\r\n      expect(userWithPosts?.posts?.[0]?.title).toBe('Post by Author');\r\n    });\r\n\r\n    it('should perform aggregations', async () => {\r\n      await db.insert('users', { name: 'Agg User 1', email: 'agg1@test.com', age: 20 });\r\n      await db.insert('users', { name: 'Agg User 2', email: 'agg2@test.com', age: 30 });\r\n      \r\n      const result = await db.query().from('users').aggregate({\r\n        count: konro.count(),\r\n        avgAge: konro.avg('age'),\r\n        sumAge: konro.sum('age'),\r\n      });\r\n      \r\n      expect(result.count).toBe(2);\r\n      expect(result.avgAge).toBe(25);\r\n      expect(result.sumAge).toBe(50);\r\n    });\r\n  });\r\n\n  describe('ID Generation', () => {\n    it('should auto-increment IDs for new CSV files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'csv_db');\n      const adapter = konro.createFileAdapter({\n        format: 'csv',\n        mode: 'on-demand',\n        multi: { dir: dbDirPath },\n      });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const user1 = await db.insert('users', { name: 'CSV User 1', email: 'csv1@test.com', age: 20 });\n      expect(user1.id).toBe(1);\n\n      const user2 = await db.insert('users', { name: 'CSV User 2', email: 'csv2@test.com', age: 21 });\n      expect(user2.id).toBe(2);\n\n      // Verify file content\n      const userFilePath = path.join(dbDirPath, 'users.csv');\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\n      const parsed = papaparse.parse(fileContent, { header: true, dynamicTyping: true, skipEmptyLines: true });\n      expect(parsed.data).toEqual(\n        expect.arrayContaining([\n          expect.objectContaining({ id: 1, name: 'CSV User 1', email: 'csv1@test.com', age: 20, isActive: true }),\n          expect.objectContaining({ id: 2, name: 'CSV User 2', email: 'csv2@test.com', age: 21, isActive: true }),\n        ])\n      );\n    });\n\n    it('should auto-increment IDs for new XLSX files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'xlsx_db');\n      const adapter = konro.createFileAdapter({\n        format: 'xlsx',\n        mode: 'on-demand',\n        multi: { dir: dbDirPath },\n      });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const user1 = await db.insert('users', { name: 'XLSX User 1', email: 'xlsx1@test.com', age: 20 });\n      expect(user1.id).toBe(1);\n\n      const user2 = await db.insert('users', { name: 'XLSX User 2', email: 'xlsx2@test.com', age: 21 });\n      expect(user2.id).toBe(2);\n\n      // Verify file content\n      const userFilePath = path.join(dbDirPath, 'users.xlsx');\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\n      const workbook = xlsx.read(fileContent, { type: 'base64' });\n      const sheetName = workbook.SheetNames[0];\n      expect(sheetName).toBeDefined();\n      const worksheet = workbook.Sheets[sheetName!];\n      expect(worksheet).toBeDefined();\n      const data = xlsx.utils.sheet_to_json(worksheet!);\n      expect(data).toEqual(\n        expect.arrayContaining([\n          expect.objectContaining({ id: 1, name: 'XLSX User 1', email: 'xlsx1@test.com', age: 20, isActive: true }),\n          expect.objectContaining({ id: 2, name: 'XLSX User 2', email: 'xlsx2@test.com', age: 21, isActive: true }),\n        ])\n      );\n    });\n\n    it('should determine lastId from existing CSV files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'csv_db_read');\n      const userFilePath = path.join(dbDirPath, 'users.csv');\n\n      // Manually create a CSV with existing data\n      await fs.mkdir(dbDirPath, { recursive: true });\n      const initialCsv = papaparse.unparse([{ id: 5, name: 'Existing User', email: 'existing@test.com', age: 50, isActive: true }]);\n      await fs.writeFile(userFilePath, initialCsv);\n\n      const adapter = konro.createFileAdapter({ format: 'csv', mode: 'on-demand', multi: { dir: dbDirPath } });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const newUser = await db.insert('users', { name: 'New CSV User', email: 'newcsv@test.com', age: 25 });\n      expect(newUser.id).toBe(6);\n    });\n\n    it('should determine lastId from existing XLSX files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'xlsx_db_read');\n      const userFilePath = path.join(dbDirPath, 'users.xlsx');\n\n      // Manually create an XLSX with existing data\n      await fs.mkdir(dbDirPath, { recursive: true });\n      const initialData = [{ id: 10, name: 'Existing XLSX User', email: 'existing_xlsx@test.com', age: 60, isActive: false }];\n      const worksheet = xlsx.utils.json_to_sheet(initialData);\n      const workbook = xlsx.utils.book_new();\n      xlsx.utils.book_append_sheet(workbook, worksheet, 'data');\n      const fileContent = xlsx.write(workbook, { bookType: 'xlsx', type: 'base64' });\n      await fs.writeFile(userFilePath, fileContent, 'utf-8');\n\n      const adapter = konro.createFileAdapter({ format: 'xlsx', mode: 'on-demand', multi: { dir: dbDirPath } });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const newUser = await db.insert('users', { name: 'New XLSX User', email: 'newxlsx@test.com', age: 35 });\n      expect(newUser.id).toBe(11);\n    });\n\n    it('should generate UUIDs for id column', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'uuid_db');\n      const adapter = konro.createFileAdapter({\n        format: 'yaml',\n        mode: 'on-demand',\n        multi: { dir: dbDirPath },\n      });\n      const db = konro.createDatabase({ schema: uuidTestSchema, adapter });\n\n      const user = await db.insert('uuid_users', { name: 'UUID User' });\n      expect(typeof user.id).toBe('string');\n      expect(user.id).toMatch(/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/);\n\n      const fileContent = await fs.readFile(path.join(dbDirPath, 'uuid_users.yaml'), 'utf-8');\n      const parsed = yaml.load(fileContent) as any;\n      expect(parsed.records[0].id).toBe(user.id);\n    });\n  });\n});"
approved: true
