uuid: 18da675c-3522-4a00-9831-2946c5ed9654
projectId: konro
createdAt: '2025-07-09T02:11:27.844Z'
linesAdded: 7
linesRemoved: 5
gitCommitMsg: 'fix(test): correct encoding for xlsx file handling in tests'
promptSummary: >-
  The user reported test failures related to XLSX file handling. The errors were
  caused by an encoding mismatch between how the test suite and the library's
  file provider were reading and writing the base64-encoded XLSX data. I have
  corrected the file encoding in the tests to align with the library's
  implementation (`utf-8`) and added checks to resolve a TypeScript error.
reasoning:
  - >-
    I see the problem. The tests are failing due to an encoding mismatch when
    handling the XLSX files, which are binary but are being transported as
    base64-encoded strings within the library. The test code was incorrectly
    writing and reading these files using `base64` encoding at the filesystem
    level, while the library's file provider consistently uses `utf-8`.
  - >-
    When the test wrote a file with `fs.writeFile(..., 'base64')`, it created a
    raw binary XLSX file. However, the library's `readFile` (using `utf-8`)
    would then read this binary file as if it were text, corrupting the data
    before it even reached the parser.
  - >-
    Conversely, when the library wrote a file (saving the base64 string as plain
    text), the test tried to read it with `fs.readFile(..., 'base64')`, which
    incorrectly tried to re-encode the already-encoded text.
  - >-
    I will correct the filesystem encoding in the test suite to `utf-8` to match
    the library's behavior. I will also fix the TypeScript error by adding the
    necessary checks to ensure the worksheet exists before trying to parse it.
operations:
  - type: write
    path: test/integration/Adapters/OnDemand.test.ts
    content: |-
      --- test/integration/Adapters/OnDemand.test.ts
      +++ test/integration/Adapters/OnDemand.test.ts
      @@ -218,11 +218,13 @@
       
             // Verify file content
             const userFilePath = path.join(dbDirPath, 'users.xlsx');
      -      const fileContent = await fs.readFile(userFilePath, 'base64');
      +      const fileContent = await fs.readFile(userFilePath, 'utf-8');
             const workbook = xlsx.read(fileContent, { type: 'base64' });
      -      const sheetName = workbook.SheetNames[0]!;
      -      const data = xlsx.utils.sheet_to_json(workbook.Sheets[sheetName]);
      -
      +      const sheetName = workbook.SheetNames[0];
      +      expect(sheetName).toBeDefined();
      +      const worksheet = workbook.Sheets[sheetName!];
      +      expect(worksheet).toBeDefined();
      +      const data = xlsx.utils.sheet_to_json(worksheet!);
             expect(data).toEqual(
               expect.arrayContaining([
                 expect.objectContaining({ id: 1, name: 'XLSX User 1', email: 'xlsx1@test.com', age: 20, isActive: true }),
      @@ -248,7 +250,7 @@
             const workbook = xlsx.utils.book_new();
             xlsx.utils.book_append_sheet(workbook, worksheet, 'data');
             const fileContent = xlsx.write(workbook, { bookType: 'xlsx', type: 'base64' });
      -      await fs.writeFile(userFilePath, fileContent, 'base64');
      +      await fs.writeFile(userFilePath, fileContent, 'utf-8');
       
             const adapter = konro.createFileAdapter({ format: 'xlsx', mode: 'on-demand', multi: { dir: dbDirPath } });
             const db = konro.createDatabase({ schema: testSchema, adapter });
    patchStrategy: new-unified
snapshot:
  test/integration/Adapters/OnDemand.test.ts: "import { describe, it, expect, beforeEach, afterEach } from 'bun:test';\r\nimport { konro } from '../../../src/index';\r\nimport { testSchema, TEST_DIR, cleanup, ensureTestDir, uuidTestSchema } from '../../util';\r\nimport path from 'path';\r\nimport { promises as fs } from 'fs';\r\nimport yaml from 'js-yaml';\r\nimport papaparse from 'papaparse';\nimport xlsx from 'xlsx';\nimport { KonroError } from '../../../src/utils/error.util';\r\nimport type { OnDemandDbContext } from '../../../src/db';\r\n\r\ndescribe('Integration > Adapters > OnDemand', () => {\r\n  const dbDirPath = path.join(TEST_DIR, 'on_demand_db');\r\n\r\n  beforeEach(ensureTestDir);\r\n  afterEach(cleanup);\r\n\r\n  describe('Initialization', () => {\r\n    it('should successfully create an on-demand db context with a multi-file adapter', () => {\r\n      const adapter = konro.createFileAdapter({\r\n        format: 'yaml',\r\n        mode: 'on-demand',\r\n        multi: { dir: dbDirPath },\r\n      });\r\n      const db = konro.createDatabase({\r\n        schema: testSchema,\r\n        adapter,\r\n      });\r\n\r\n      expect(db).toBeDefined();\r\n      expect(db.adapter.mode).toBe('on-demand');\r\n      expect(typeof db.insert).toBe('function');\r\n      expect(typeof db.query).toBe('function');\r\n    });\r\n\r\n    it('should throw an error when creating an on-demand db context with a single-file adapter', () => {\r\n      expect(() => {\r\n        konro.createFileAdapter({\r\n          format: 'json',\r\n          mode: 'on-demand',\r\n          single: { filepath: path.join(dbDirPath, 'db.json') },\r\n        });\r\n      }).toThrow(KonroError(\"The 'on-demand' mode requires the 'multi-file' storage strategy.\"));\r\n    });\r\n  });\r\n\r\n  describe('Unsupported Operations', () => {\r\n    const adapter = konro.createFileAdapter({\r\n      format: 'yaml',\r\n      mode: 'on-demand',\r\n      multi: { dir: dbDirPath },\r\n    });\r\n    const db = konro.createDatabase({\r\n      schema: testSchema,\r\n      adapter,\r\n    });\r\n    \r\n    it('should reject db.read()', async () => {\r\n      expect(db.read()).rejects.toThrow(KonroError(\"This method is not supported in 'on-demand' mode.\"));\r\n    });\r\n\r\n    it('should reject db.write()', async () => {\r\n      expect(db.write()).rejects.toThrow(KonroError(\"This method is not supported in 'on-demand' mode.\"));\r\n    });\r\n  });\r\n\r\n  describe('CRUD Operations', () => {\r\n    let db: OnDemandDbContext<typeof testSchema>;\r\n\r\n    beforeEach(() => {\r\n      const adapter = konro.createFileAdapter({\r\n        format: 'yaml',\r\n        mode: 'on-demand',\r\n        multi: { dir: dbDirPath },\r\n      });\r\n      db = konro.createDatabase({\r\n        schema: testSchema,\r\n        adapter,\r\n      });\r\n    });\r\n\r\n    it('should insert a record and write it to the correct file', async () => {\r\n      const user = await db.insert('users', {\r\n        name: 'OnDemand User',\r\n        email: 'ondemand@test.com',\r\n        age: 25,\r\n      });\r\n\r\n      expect(user.id).toBe(1);\r\n      expect(user.name).toBe('OnDemand User');\r\n\r\n      const userFilePath = path.join(dbDirPath, 'users.yaml');\r\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\r\n      const parsedContent = yaml.load(fileContent) as any;\r\n\r\n      expect(parsedContent.records.length).toBe(1);\r\n      expect(parsedContent.records[0].name).toBe('OnDemand User');\r\n      expect(parsedContent.meta.lastId).toBe(1);\r\n    });\r\n\r\n    it('should query for records', async () => {\r\n      await db.insert('users', { name: 'Query User', email: 'q@test.com', age: 30 });\r\n      \r\n      const user = await db.query().from('users').where({ name: 'Query User' }).first();\r\n      expect(user).toBeDefined();\r\n      expect(user?.name).toBe('Query User');\r\n\r\n      const allUsers = await db.query().from('users').all();\r\n      expect(allUsers.length).toBe(1);\r\n    });\r\n\r\n    it('should update a record', async () => {\r\n      const user = await db.insert('users', { name: 'Update Me', email: 'u@test.com', age: 40 });\r\n      \r\n      const updatedUsers = await db.update('users')\r\n        .set({ name: 'Updated Name' })\r\n        .where({ id: user.id });\r\n\r\n      expect(updatedUsers.length).toBe(1);\r\n      expect(updatedUsers[0]?.name).toBe('Updated Name');\r\n\r\n      const userFilePath = path.join(dbDirPath, 'users.yaml');\r\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\r\n      const parsedContent = yaml.load(fileContent) as any;\r\n      \r\n      expect(parsedContent.records[0].name).toBe('Updated Name');\r\n    });\r\n\r\n    it('should delete a record', async () => {\r\n      const user = await db.insert('users', { name: 'Delete Me', email: 'd@test.com', age: 50 });\r\n      \r\n      await db.delete('users').where({ id: user.id });\r\n\r\n      const users = await db.query().from('users').all();\r\n      expect(users.length).toBe(0);\r\n\r\n      const userFilePath = path.join(dbDirPath, 'users.yaml');\r\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\r\n      const parsedContent = yaml.load(fileContent) as any;\r\n      \r\n      expect(parsedContent.records.length).toBe(0);\r\n    });\r\n    \r\n    it('should query with relations', async () => {\r\n      const user = await db.insert('users', { name: 'Author', email: 'author@test.com', age: 35 });\r\n      await db.insert('posts', { title: 'Post by Author', content: '...', authorId: user.id });\r\n      await db.insert('posts', { title: 'Another Post', content: '...', authorId: user.id });\r\n      \r\n      const userWithPosts = await db.query().from('users').where({ id: user.id }).with({ posts: true }).first();\r\n      \r\n      expect(userWithPosts).toBeDefined();\r\n      expect(userWithPosts?.name).toBe('Author');\r\n      expect(userWithPosts?.posts).toBeInstanceOf(Array);\r\n      expect(userWithPosts?.posts?.length).toBe(2);\r\n      expect(userWithPosts?.posts?.[0]?.title).toBe('Post by Author');\r\n    });\r\n\r\n    it('should perform aggregations', async () => {\r\n      await db.insert('users', { name: 'Agg User 1', email: 'agg1@test.com', age: 20 });\r\n      await db.insert('users', { name: 'Agg User 2', email: 'agg2@test.com', age: 30 });\r\n      \r\n      const result = await db.query().from('users').aggregate({\r\n        count: konro.count(),\r\n        avgAge: konro.avg('age'),\r\n        sumAge: konro.sum('age'),\r\n      });\r\n      \r\n      expect(result.count).toBe(2);\r\n      expect(result.avgAge).toBe(25);\r\n      expect(result.sumAge).toBe(50);\r\n    });\r\n  });\r\n\n  describe('ID Generation', () => {\n    it('should auto-increment IDs for new CSV files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'csv_db');\n      const adapter = konro.createFileAdapter({\n        format: 'csv',\n        mode: 'on-demand',\n        multi: { dir: dbDirPath },\n      });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const user1 = await db.insert('users', { name: 'CSV User 1', email: 'csv1@test.com', age: 20 });\n      expect(user1.id).toBe(1);\n\n      const user2 = await db.insert('users', { name: 'CSV User 2', email: 'csv2@test.com', age: 21 });\n      expect(user2.id).toBe(2);\n\n      // Verify file content\n      const userFilePath = path.join(dbDirPath, 'users.csv');\n      const fileContent = await fs.readFile(userFilePath, 'utf-8');\n      const parsed = papaparse.parse(fileContent, { header: true, dynamicTyping: true, skipEmptyLines: true });\n      expect(parsed.data).toEqual(\n        expect.arrayContaining([\n          expect.objectContaining({ id: 1, name: 'CSV User 1', email: 'csv1@test.com', age: 20, isActive: true }),\n          expect.objectContaining({ id: 2, name: 'CSV User 2', email: 'csv2@test.com', age: 21, isActive: true }),\n        ])\n      );\n    });\n\n    it('should auto-increment IDs for new XLSX files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'xlsx_db');\n      const adapter = konro.createFileAdapter({\n        format: 'xlsx',\n        mode: 'on-demand',\n        multi: { dir: dbDirPath },\n      });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const user1 = await db.insert('users', { name: 'XLSX User 1', email: 'xlsx1@test.com', age: 20 });\n      expect(user1.id).toBe(1);\n\n      const user2 = await db.insert('users', { name: 'XLSX User 2', email: 'xlsx2@test.com', age: 21 });\n      expect(user2.id).toBe(2);\n\n      // Verify file content\n      const userFilePath = path.join(dbDirPath, 'users.xlsx');\n      const fileContent = await fs.readFile(userFilePath, 'base64');\n      const workbook = xlsx.read(fileContent, { type: 'base64' });\n      const sheetName = workbook.SheetNames[0]!;\n      const data = xlsx.utils.sheet_to_json(workbook.Sheets[sheetName]);\n\n      expect(data).toEqual(\n        expect.arrayContaining([\n          expect.objectContaining({ id: 1, name: 'XLSX User 1', email: 'xlsx1@test.com', age: 20, isActive: true }),\n          expect.objectContaining({ id: 2, name: 'XLSX User 2', email: 'xlsx2@test.com', age: 21, isActive: true }),\n        ])\n      );\n    });\n\n    it('should determine lastId from existing CSV files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'csv_db_read');\n      const userFilePath = path.join(dbDirPath, 'users.csv');\n\n      // Manually create a CSV with existing data\n      await fs.mkdir(dbDirPath, { recursive: true });\n      const initialCsv = papaparse.unparse([{ id: 5, name: 'Existing User', email: 'existing@test.com', age: 50, isActive: true }]);\n      await fs.writeFile(userFilePath, initialCsv);\n\n      const adapter = konro.createFileAdapter({ format: 'csv', mode: 'on-demand', multi: { dir: dbDirPath } });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const newUser = await db.insert('users', { name: 'New CSV User', email: 'newcsv@test.com', age: 25 });\n      expect(newUser.id).toBe(6);\n    });\n\n    it('should determine lastId from existing XLSX files', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'xlsx_db_read');\n      const userFilePath = path.join(dbDirPath, 'users.xlsx');\n\n      // Manually create an XLSX with existing data\n      await fs.mkdir(dbDirPath, { recursive: true });\n      const initialData = [{ id: 10, name: 'Existing XLSX User', email: 'existing_xlsx@test.com', age: 60, isActive: false }];\n      const worksheet = xlsx.utils.json_to_sheet(initialData);\n      const workbook = xlsx.utils.book_new();\n      xlsx.utils.book_append_sheet(workbook, worksheet, 'data');\n      const fileContent = xlsx.write(workbook, { bookType: 'xlsx', type: 'base64' });\n      await fs.writeFile(userFilePath, fileContent, 'base64');\n\n      const adapter = konro.createFileAdapter({ format: 'xlsx', mode: 'on-demand', multi: { dir: dbDirPath } });\n      const db = konro.createDatabase({ schema: testSchema, adapter });\n\n      const newUser = await db.insert('users', { name: 'New XLSX User', email: 'newxlsx@test.com', age: 35 });\n      expect(newUser.id).toBe(11);\n    });\n\n    it('should generate UUIDs for id column', async () => {\n      const dbDirPath = path.join(TEST_DIR, 'uuid_db');\n      const adapter = konro.createFileAdapter({\n        format: 'yaml',\n        mode: 'on-demand',\n        multi: { dir: dbDirPath },\n      });\n      const db = konro.createDatabase({ schema: uuidTestSchema, adapter });\n\n      const user = await db.insert('uuid_users', { name: 'UUID User' });\n      expect(typeof user.id).toBe('string');\n      expect(user.id).toMatch(/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/);\n\n      const fileContent = await fs.readFile(path.join(dbDirPath, 'uuid_users.yaml'), 'utf-8');\n      const parsed = yaml.load(fileContent) as any;\n      expect(parsed.records[0].id).toBe(user.id);\n    });\n  });\n});"
approved: true
